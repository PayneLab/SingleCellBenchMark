{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mokapot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path\n",
    "import data_loader as dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this function is to clean up the original 'before' data so that we are not counting decoys or duplicate scans. Mokapot needs the decoys, so they are only removed from the 'before' data.\n",
    "Any scans with a \"nan\" value in the precursor intensity column are replaced with a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df, cutoff, prob_column='PEP'):\n",
    "    #drop decoys\n",
    "    df = df[df[\"decoy\"]==False]\n",
    "    #sort by qvalue\n",
    "    df = df.sort_values(prob_column)\n",
    "    #drop duplicate scans\n",
    "    df = df.drop_duplicates(subset=[\"scan\"], keep=\"first\") #keep highest scoring\n",
    "    #replacing any precursor intensity that have a \"nan\" value with a 0\n",
    "    df['Precursor Intensity'].replace(np.nan, 0, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MokaPot needs a column that notates whether a scan was decoy or not. The \"make_decoy_col_maxquant\" function generates that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decoy_col_maxquant(row):\n",
    "    if row[\"Reverse\"].startswith(\"+\"):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read in the data and clean it up before we run it thorugh MokaPot. \n",
    "We drop any duplicate scans before the data is fed into MokaPot. We also change the scan number name so that all of our files will match in the end so we can merge them into one megascript. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the data and formatting it for MokaPot\n",
    "def get_data_for_MokaPot(filename):\n",
    "    mq_df =  dl.clean_maxquant(filename)\n",
    "    mq_df[\"target_column\"] = mq_df.apply(make_decoy_col_maxquant, axis = 1)\n",
    "    \n",
    "    \n",
    "    #Dropping any rows that are missing the sequence\n",
    "    mq_df['Sequence'].replace(' ', np.nan, inplace = True)\n",
    "    mq_df.dropna(subset=['Sequence'], inplace=True)\n",
    "    \n",
    "    #sort and drop duplicate scans\n",
    "    mq_df = mq_df.sort_values('PEP')\n",
    "    mq_df = mq_df.drop_duplicates(subset=[\"scan\"], keep=\"first\") #keep highest scoring\n",
    "    \n",
    "    #replacing any precursor intensity that have a \"nan\" value with a 0\n",
    "    mq_df['Precursor Intensity'].replace(np.nan, 0, inplace = True)\n",
    "    \n",
    "    \n",
    "    mq_df = mq_df.rename(columns = {\"scan\": \"ScanNr\"})\n",
    "    \n",
    "    return mq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us back a dataset that drops the decoys, duplicate scans, and rows without a sequence number. It has not been ran through MokaPot. The purpose of this is to be able to count how many scans we originally have at or under a specific cutoff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PreMokaPot_data(filename):\n",
    "    mq_df =  dl.clean_maxquant(filename)\n",
    "    \n",
    "#Formatting and dropping any rows that are missing the sequence (Do we still want this??)\n",
    "    mq_df['Sequence'].replace(' ', np.nan, inplace = True)\n",
    "    mq_df.dropna(subset=['Sequence'], inplace=True)\n",
    "    \n",
    "    mq_df = filter_data(mq_df, 0.01)\n",
    "    \n",
    "    return  mq_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the files we want to run through MokaPot here \n",
    "file_names = [\"2ng_rep1\", \"2ng_rep2\", \"2ng_rep3\", \"2ng_rep4\", \"2ng_rep5\", \"2ng_rep6\",\n",
    "             \"0.2ng_rep1\", \"0.2ng_rep2\", \"0.2ng_rep3\", \"0.2ng_rep4\", \"0.2ng_rep5\", \"0.2ng_rep6\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we run each input file through MokaPot. Each file we read in is analyzed and the results are saved in a seperate output file.\n",
    "\n",
    "MokaPot requires feature columns that it uses to give each scan a new q value score. The columns from MaxQuant that we have chosen to use as features are: 'Precursor Intensity', 'Score','Length', 'Missed cleavages', 'm/z', 'Mass', 'Retention time', and 'Delta score'. 'Charge' is also used as an one hot encoding per the recommendation of the writer of MokaPot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of PSMs found at or above 0.01 for file 2ng_rep1:\n",
      "\tMaxQuant: 7900\n",
      "\tMaxQuant and MokaPot: 12050\n",
      "\n",
      "The number of PSMs found at or above 0.01 for file 2ng_rep2:\n",
      "\tMaxQuant: 8210\n",
      "\tMaxQuant and MokaPot: 11372\n",
      "\n",
      "The number of PSMs found at or above 0.01 for file 2ng_rep3:\n",
      "\tMaxQuant: 6067\n",
      "\tMaxQuant and MokaPot: 9449\n",
      "\n",
      "The number of PSMs found at or above 0.01 for file 2ng_rep4:\n",
      "\tMaxQuant: 6401\n",
      "\tMaxQuant and MokaPot: 9145\n",
      "\n",
      "The number of PSMs found at or above 0.01 for file 2ng_rep5:\n",
      "\tMaxQuant: 11196\n",
      "\tMaxQuant and MokaPot: 14226\n",
      "\n",
      "The number of PSMs found at or above 0.01 for file 2ng_rep6:\n",
      "\tMaxQuant: 10361\n",
      "\tMaxQuant and MokaPot: 13270\n",
      "\n",
      "The number of PSMs found at or above 0.01 for file 0.2ng_rep1:\n",
      "\tMaxQuant: 4096\n",
      "\tMaxQuant and MokaPot: 6172\n",
      "\n",
      "The number of PSMs found at or above 0.01 for file 0.2ng_rep2:\n",
      "\tMaxQuant: 4077\n",
      "\tMaxQuant and MokaPot: 6035\n",
      "\n",
      "The number of PSMs found at or above 0.01 for file 0.2ng_rep3:\n",
      "\tMaxQuant: 2809\n",
      "\tMaxQuant and MokaPot: 4429\n",
      "\n",
      "The number of PSMs found at or above 0.01 for file 0.2ng_rep4:\n",
      "\tMaxQuant: 2637\n",
      "\tMaxQuant and MokaPot: 4282\n",
      "\n",
      "The number of PSMs found at or above 0.01 for file 0.2ng_rep5:\n",
      "\tMaxQuant: 3053\n",
      "\tMaxQuant and MokaPot: 4669\n",
      "\n",
      "The number of PSMs found at or above 0.01 for file 0.2ng_rep6:\n",
      "\tMaxQuant: 2647\n",
      "\tMaxQuant and MokaPot: 4028\n"
     ]
    }
   ],
   "source": [
    "for file in file_names:\n",
    "    mq_cleaned_df = get_PreMokaPot_data(file)\n",
    "    mq_df = get_data_for_MokaPot(file)\n",
    "\n",
    "    charge_feat = pd.get_dummies(mq_df[\"Charge\"], prefix=\"Charge\")\n",
    "    mq_df = pd.concat([mq_df, charge_feat], axis=1)\n",
    "\n",
    "    mq_for_MP = mokapot.dataset.LinearPsmDataset(mq_df, target_column = \"target_column\", spectrum_columns = \"ScanNr\", \n",
    "                                                     peptide_column = \"peptide\", protein_column=None, \n",
    "                                                     group_column=None, feature_columns=(list(charge_feat.columns) + [\"Precursor Intensity\", 'Score', \n",
    "                                                                                                                      'Length', 'Missed cleavages', 'm/z', 'Mass', \n",
    "                                                                                                                      'Retention time', 'Delta score', ]), copy_data=True)\n",
    "    results, models = mokapot.brew(mq_for_MP)\n",
    "\n",
    "    results_df = results.psms\n",
    "    results_df.to_csv(\"MokaPot_Output/MaxQuant/mq_\" + file + \".csv\")\n",
    "    \n",
    "    print(\"\\n\" + \"The number of PSMs found at or above 0.01 for file \" + file + \":\")   \n",
    "    print(\"\\t\" + \"MaxQuant: \" + str(len(mq_cleaned_df[mq_cleaned_df['PEP'] <= 0.01])))\n",
    "    print(\"\\t\"\"MaxQuant and MokaPot: \" + str(len(results.psms[results.psms['mokapot q-value'] <= 0.01]))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
