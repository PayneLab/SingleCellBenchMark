{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mokapot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path\n",
    "import data_loader as dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this function is to clean up the original data so that we are not counting decoys or duplicate scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df, cutoff, prob_column='PEP'):\n",
    "    #drop decoys\n",
    "    df = df[df[\"decoy\"]==False]\n",
    "    #sort by qvalue\n",
    "    df = df.sort_values(prob_column)\n",
    "    #drop duplicate scans\n",
    "    df = df.drop_duplicates(subset=[\"scan\"], keep=\"first\") #keep highest coring\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we get ride of decoys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decoy_col_maxquant(row):\n",
    "    if row[\"Proteins\"].startswith(\"REV\"):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read in the data and clean it up before we run it thorugh MokaPot. \n",
    "*Need to not drop columns and instead choose which ones we will give to it instead. \n",
    "We also change the scan number name so that all of our files will match in the end so we can merge them into one megascript. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the data and formatting it for MokaPot\n",
    "def get_data_for_MokaPot(filename):\n",
    "    mq_df =  dl.clean_maxquant(filename)\n",
    "    mq_df[\"target_column\"] = mq_df.apply(make_decoy_col_maxquant, axis = 1)\n",
    "    \n",
    "    \n",
    "    #Dropping any rows that are missing the sequence\n",
    "    #mq_df['Sequence'].replace(' ', np.nan, inplace = True)\n",
    "    #mq_df.dropna(subset=['Sequence'], inplace=True)\n",
    "    \n",
    "    mq_df = mq_df.rename(columns = {\"scan\": \"ScanNr\"})\n",
    "    \n",
    "    #dropping columns because they are not numerical entries, or they are missing values.\n",
    "    #Change this to selecting what colums we are going to give it versus just dropping everything\n",
    "    mq_df = mq_df.drop(columns = {\n",
    "       'Identified', 'Sequence', 'Mass analyzer', 'Modifications','Modified sequence','Type','Fragmentation',\n",
    "       'Proteins','Raw file', 'decoy', 'Elapsed time','Matched','Reverse','Mass','Precursor intensity',\n",
    "        'Precursor apex fraction', 'Precursor apex offset time', 'Score', 'PEP', 'Reporter PIF', \n",
    "        'Reporter fraction', 'Intens Comp Factor', 'CTCD Comp'})\n",
    "    \n",
    "    #Keep: pre intensity, score\n",
    "    #**Fix in parser so that anything without sequence is gone. \n",
    "    \n",
    "    return mq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us back a dataset that has had the decoys, duplicate scans, and rows without a sequence number dropped.It has not been ran through MokaPot. The purpose of this is to be able to count how many scans we originally have at or under a specific cutoff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PreMokaPot_data(filename):\n",
    "    mq_df =  dl.clean_maxquant(filename)\n",
    "    \n",
    "#Formatting and dropping any rows that are missing the sequence (Do we still want this??)\n",
    "    mq_df['Sequence'].replace(' ', np.nan, inplace = True)\n",
    "    mq_df.dropna(subset=['Sequence'], inplace=True)\n",
    "    \n",
    "    mq_df = filter_data(mq_df, 0.01)\n",
    "    \n",
    "    return  mq_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is code that was taken from the MokaPot program. It formats the data for the graphs. THe purpose of the graphs is to compare the preMokaPot data to the postMokaPot data and compare if we are getting more scans at or below a certain cutoff after running data through MokaPot. \n",
    "MaxQuant does not have a q value, so instead we are using the PEP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_qvalues(df, level=\"psms\", threshold=0.01, ax=None, **kwargs):\n",
    "    qvals = df[\"PEP\"]\n",
    "\n",
    "    ax = plot_qvalues(qvals, threshold=threshold, ax=ax, **kwargs)\n",
    "    ax.set_xlabel(\"q-value\")\n",
    "    ax.set_ylabel(f\"Accepted {self._level_labs[level]}\")\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_qvalues(qvalues, threshold=0.01, ax=None, **kwargs):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Calculate cumulative targets at each q-value\n",
    "    qvals = pd.Series(qvalues, name=\"qvalue\")\n",
    "    qvals = qvals.sort_values(ascending=True).to_frame()\n",
    "    qvals[\"target\"] = 1\n",
    "    qvals[\"num\"] = qvals[\"target\"].cumsum()\n",
    "    qvals = qvals.groupby([\"qvalue\"]).max().reset_index()\n",
    "    qvals = qvals[[\"qvalue\", \"num\"]]\n",
    "\n",
    "    zero = pd.DataFrame({\"qvalue\": qvals[\"qvalue\"][0], \"num\": 0}, index=[-1])\n",
    "    qvals = pd.concat([zero, qvals], sort=True).reset_index(drop=True)\n",
    "\n",
    "    xmargin = threshold * 0.05\n",
    "    ymax = qvals.num[qvals[\"qvalue\"] <= (threshold + xmargin)].max()\n",
    "    ymargin = ymax * 0.05\n",
    "\n",
    "    # Set margins\n",
    "    curr_ylims = ax.get_ylim()\n",
    "    if curr_ylims[1] < ymax + ymargin:\n",
    "        ax.set_ylim(0 - ymargin, ymax + ymargin)\n",
    "\n",
    "    ax.set_xlim(0 - xmargin, threshold + xmargin)\n",
    "    ax.set_xlabel(\"q-value\")\n",
    "    ax.set_ylabel(f\"Discoveries\")\n",
    "\n",
    "    ax.step(qvals[\"qvalue\"].values, qvals.num.values, where=\"post\", **kwargs)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the files we want to run through MokaPot here \n",
    "file_names = [\"2ng_rep1\", \"2ng_rep2\", \"2ng_rep3\", \"2ng_rep4\", \"2ng_rep5\", \"2ng_rep6\",\n",
    "             \"0.2ng_rep1\", \"0.2ng_rep2\", \"0.2ng_rep3\", \"0.2ng_rep4\", \"0.2ng_rep5\", \"0.2ng_rep6\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run each file through MokaPot and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data_loader.py:202: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['temp_peptide'] = df.apply(lambda row: format_oxidation(row, \"Modified sequence\", \"(Oxidation (M))\"), axis=1)\n",
      "../data_loader.py:203: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"temp_peptide\"] = df[\"temp_peptide\"].str[1:-1]\n",
      "../data_loader.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Reverse'] = df['Reverse'].astype(str)\n",
      "../data_loader.py:206: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"decoy\"] = df.apply(lambda row: make_decoy_col_maxquant(row), axis=1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'startswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6a8c1b8c8a80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmq_cleaned_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_PreMokaPot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmq_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_for_MokaPot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     mq_for_MP = mokapot.dataset.LinearPsmDataset(mq_df, target_column = \"target_column\", spectrum_columns = \"ScanNr\", \n",
      "\u001b[0;32m<ipython-input-4-73c10195b62b>\u001b[0m in \u001b[0;36mget_data_for_MokaPot\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data_for_MokaPot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmq_df\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_maxquant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmq_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target_column\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmq_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_decoy_col_maxquant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6876\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6877\u001b[0m         )\n\u001b[0;32m-> 6878\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6880\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 result = libreduction.compute_reduction(\n\u001b[0m\u001b[1;32m    296\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 )\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.compute_reduction\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-dbb6b8ab8227>\u001b[0m in \u001b[0;36mmake_decoy_col_maxquant\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_decoy_col_maxquant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Proteins\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"REV\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'startswith'"
     ]
    }
   ],
   "source": [
    "for file in file_names:\n",
    "    mq_cleaned_df = get_PreMokaPot_data(file)\n",
    "    mq_df = get_data_for_MokaPot(file)\n",
    "\n",
    "    mq_for_MP = mokapot.dataset.LinearPsmDataset(mq_df, target_column = \"target_column\", spectrum_columns = \"ScanNr\", \n",
    "                                                 peptide_column = \"peptide\", protein_column=None, \n",
    "                                                 group_column=None, feature_columns=None, copy_data=True)\n",
    "    results, models = mokapot.brew(mq_for_MP)\n",
    "\n",
    "    results_df = results.psms\n",
    "    results_df.to_csv(\"MokaPot_Output/MaxQuant/mq_\" + file + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mq_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we graph the results for pre and post MokaPot. We are plotting MaxQuant's PEP values against the q values that MokaPot improved on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_qvalues(mq_cleaned_df[\"PEP\"], label=\"Pre-mokapot\")\n",
    "plt.title(\"Mokapot vs MaxQuant\")\n",
    "results.plot_qvalues(label=\"mokapot\")\n",
    "plt.legend([\"preMoka\", \"Mokapot\"])\n",
    "plt.vlines(x = 0.01, ymin = 0, ymax = 12000)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of PSMs found at or above 0.01: \") \n",
    "      \n",
    "print(\"\\t\" + \"MaxQuant: \" + str(len(mq_cleaned_df[mq_cleaned_df['PEP'] <= 0.01])))\n",
    "\n",
    "print(\"\\t\"\"MaxQuant and MokaPot: \" + str(len(results.psms[results.psms['mokapot q-value'] <= 0.01])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mq_df =  dl.clean_maxquant(\"2ng_rep1\")\n",
    "mq_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
