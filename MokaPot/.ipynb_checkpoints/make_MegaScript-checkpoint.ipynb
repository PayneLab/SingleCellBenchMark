{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mokapot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path\n",
    "import data_loader as dl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this function is to clean up the original 'before' data so that we are not counting decoys or duplicate scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df, prob_column):\n",
    "    #drop decoys\n",
    "    df = df[df[\"decoy\"]==False]\n",
    "    #sort by qvalue\n",
    "    df = df.sort_values(prob_column)\n",
    "    #drop duplicate scans\n",
    "    df = df.drop_duplicates(subset=[\"scan\"], keep=\"first\") #keep highest scoring\n",
    "    #rename scan column\n",
    "    df = df.rename(columns = {\"scan\": \"ScanNr\"})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next functions read in the dataframes that hold the 'before' data. This is the data that has not been run through MokaPot. We will use this to compare whether MokaPot was able to improve the number or scans below a certain cutoff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in and formatting the original MetaMorpheus data\n",
    "def get_orgininal_mm_data(file):\n",
    "    mm_original_df = dl.clean_metamorph(file)\n",
    "    mm_original_df = filter_data( mm_original_df, \"QValue\")\n",
    "    \n",
    "    #filter out just the ScanNr and QValue and/or PEP columns\n",
    "    mm_original_df = mm_original_df.filter(items = ['ScanNr', 'peptide', 'QValue', 'PEP'])\n",
    "    \n",
    "    return mm_original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in and formatting the orginial MsFragger data\n",
    "def set_probablility(row):\n",
    "    new_prob = 1 - row[\"PeptideProphet Probability\"]\n",
    "    return new_prob\n",
    "\n",
    "#pulling only scan numbers out\n",
    "def extractScanNum(row):\n",
    "    string = row\n",
    "    spot = string.find('.')\n",
    "    new_st = string[spot + 1:]\n",
    "    spot = new_st.find('.')\n",
    "    final_st = new_st[:spot]\n",
    "    \n",
    "    if final_st[0] == \"0\":\n",
    "        final_st = final_st[1:]\n",
    "    return final_st\n",
    "\n",
    "def get_original_msf_data(file):\n",
    "    msf_original_df = dl.clean_msfragger(file)\n",
    "    \n",
    "    #Extracting scan number from file number\n",
    "    msf_original_df['scan'] =msf_original_df['scan'].apply(extractScanNum) \n",
    "    \n",
    "    msf_original_df = filter_data(msf_original_df, 'PeptideProphet Probability')\n",
    "    \n",
    "    #Changing the probabilities to the same scale all the other tools use \n",
    "    msf_original_df[\"Updated_probability\"] =  msf_original_df.apply(set_probablility, 1)\n",
    "    \n",
    "    #filter out just the ScanNr, peptide, and probability column\n",
    "    msf_original_df = msf_original_df.filter(['ScanNr', 'peptide','Updated_probability'])\n",
    "    \n",
    "    return  msf_original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in and formatting the orginial MsgfPlus data\n",
    "def get_original_msg_data(file):\n",
    "    msg_original_df = dl.clean_msgfplus(file)\n",
    "    msg_original_df = filter_data(msg_original_df, \"QValue\")\n",
    "    \n",
    "    #filter out just the ScanNr, peptide, and QValue columns\n",
    "    msg_original_df = msg_original_df.filter([\"ScanNr\", 'peptide', \"QValue\"])\n",
    "    \n",
    "    return msg_original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in and formatting the orginial MaxQuant data\n",
    "def get_original_mq_data(file):\n",
    "     mq_original_df =  dl.clean_maxquant(file)\n",
    "    \n",
    "#Formatting and dropping any rows that are missing the sequence\n",
    "     mq_original_df['Sequence'].replace(' ', np.nan, inplace = True)\n",
    "     mq_original_df.dropna(subset=['Sequence'], inplace=True)\n",
    "    \n",
    "     mq_original_df = filter_data(mq_original_df, 'PEP')\n",
    "    \n",
    "    #filter out just the ScanNr, peptide and PEP columns\n",
    "     mq_original_df = mq_original_df.filter([\"ScanNr\", 'peptide', \"PEP\"])\n",
    "    \n",
    "     return  mq_original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in and formatting the data from PD\n",
    "def get_pd_data(file):\n",
    "    pd_df = dl.clean_proteome_discover(file)\n",
    "    pd_df = pd_df.sort_values(\"Percolator q-Value\")\n",
    "    pd_df = pd_df.rename(columns = {\"First Scan\": \"ScanNr\"})\n",
    "    pd_df = pd_df.filter(['ScanNr', 'Percolator q-Value'])\n",
    "    pd_df.drop_duplicates(subset=[\"ScanNr\"], keep=\"first\", inplace=True)\n",
    "\n",
    "    return pd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell has the names to all the saved data files after the data has been ran through MokaPot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preMP_data = [\"2ng_rep1\", \"2ng_rep2\", \"2ng_rep3\", \"2ng_rep4\", \"2ng_rep5\", \"2ng_rep6\",\n",
    "             \"0.2ng_rep1\", \"0.2ng_rep2\", \"0.2ng_rep3\", \"0.2ng_rep4\", \"0.2ng_rep5\", \"0.2ng_rep6\"]\n",
    "\n",
    "    \n",
    "msg_postMP_data = {\"2ng_rep1\" : \"MokaPot_Output/MsgfPlus/msg_2ng_rep1.csv\", \"2ng_rep2\" : \"MokaPot_Output/MsgfPlus/msg_2ng_rep2.csv\", \"2ng_rep3\" : \"MokaPot_Output/MsgfPlus/msg_2ng_rep3.csv\" , \n",
    "                   \"2ng_rep4\" : \"MokaPot_Output/MsgfPlus/msg_2ng_rep4.csv\", \"2ng_rep5\" : \"MokaPot_Output/MsgfPlus/msg_2ng_rep5.csv\", \"2ng_rep6\": \"MokaPot_Output/MsgfPlus/msg_2ng_rep6.csv\",\n",
    "                   \"0.2ng_rep1\" : \"MokaPot_Output/MsgfPlus/msg_0.2ng_rep1.csv\", \"0.2ng_rep2\" : \"MokaPot_Output/MsgfPlus/msg_0.2ng_rep2.csv\", \"0.2ng_rep3\": \"MokaPot_Output/MsgfPlus/msg_0.2ng_rep3.csv\", \n",
    "                   \"0.2ng_rep4\": \"MokaPot_Output/MsgfPlus/msg_0.2ng_rep4.csv\", \"0.2ng_rep5\": \"MokaPot_Output/MsgfPlus/msg_0.2ng_rep5.csv\", \"0.2ng_rep6\": \"MokaPot_Output/MsgfPlus/msg_0.2ng_rep6.csv\"}\n",
    "\n",
    "mq_postMP_data = {\"2ng_rep1\" : \"MokaPot_Output/MaxQuant/mq_2ng_rep1.csv\", \"2ng_rep2\" : \"MokaPot_Output/MaxQuant/mq_2ng_rep2.csv\", \"2ng_rep3\" : \"MokaPot_Output/MaxQuant/mq_2ng_rep3.csv\" , \n",
    "                   \"2ng_rep4\" : \"MokaPot_Output/MaxQuant/mq_2ng_rep4.csv\", \"2ng_rep5\" : \"MokaPot_Output/MaxQuant/mq_2ng_rep5.csv\", \"2ng_rep6\": \"MokaPot_Output/MaxQuant/mq_2ng_rep6.csv\",\n",
    "                   \"0.2ng_rep1\" : \"MokaPot_Output/MaxQuant/mq_0.2ng_rep1.csv\", \"0.2ng_rep2\" : \"MokaPot_Output/MaxQuant/mq_0.2ng_rep2.csv\", \"0.2ng_rep3\": \"MokaPot_Output/MaxQuant/mq_0.2ng_rep3.csv\", \n",
    "                   \"0.2ng_rep4\": \"MokaPot_Output/MaxQuant/mq_0.2ng_rep4.csv\", \"0.2ng_rep5\": \"MokaPot_Output/MaxQuant/mq_0.2ng_rep5.csv\", \"0.2ng_rep6\": \"MokaPot_Output/MaxQuant/mq_0.2ng_rep6.csv\"}\n",
    "\n",
    "mm_postMP_data = {\"2ng_rep1\" : \"MokaPot_Output/MetaMorpheus/mm_2ng_rep1.csv\", \"2ng_rep2\" : \"MokaPot_Output/MetaMorpheus/mm_2ng_rep2.csv\", \"2ng_rep3\" : \"MokaPot_Output/MetaMorpheus/mm_2ng_rep3.csv\" , \n",
    "                   \"2ng_rep4\" : \"MokaPot_Output/MetaMorpheus/mm_2ng_rep4.csv\", \"2ng_rep5\" : \"MokaPot_Output/MetaMorpheus/mm_2ng_rep5.csv\", \"2ng_rep6\": \"MokaPot_Output/MetaMorpheus/mm_2ng_rep6.csv\",\n",
    "                   \"0.2ng_rep1\" : \"MokaPot_Output/MetaMorpheus/mm_0.2ng_rep1.csv\", \"0.2ng_rep2\" : \"MokaPot_Output/MetaMorpheus/mm_0.2ng_rep2.csv\", \"0.2ng_rep3\": \"MokaPot_Output/MetaMorpheus/mm_0.2ng_rep3.csv\", \n",
    "                   \"0.2ng_rep4\": \"MokaPot_Output/MetaMorpheus/mm_0.2ng_rep4.csv\", \"0.2ng_rep5\": \"MokaPot_Output/MetaMorpheus/mm_0.2ng_rep5.csv\", \"0.2ng_rep6\": \"MokaPot_Output/MetaMorpheus/mm_0.2ng_rep6.csv\"}\n",
    "\n",
    "msf_postMP_data = {\"2ng_rep1\" : \"MokaPot_Output/MsFragger/msf_2ng_rep1.csv\", \"2ng_rep2\" : \"MokaPot_Output/MsFragger/msf_2ng_rep2.csv\", \"2ng_rep3\" : \"MokaPot_Output/MsFragger/msf_2ng_rep3.csv\" , \n",
    "                   \"2ng_rep4\" : \"MokaPot_Output/MsFragger/msf_2ng_rep4.csv\", \"2ng_rep5\" : \"MokaPot_Output/MsFragger/msf_2ng_rep5.csv\", \"2ng_rep6\": \"MokaPot_Output/MsFragger/msf_2ng_rep6.csv\",\n",
    "                   \"0.2ng_rep1\" : \"MokaPot_Output/MsFragger/msf_0.2ng_rep1.csv\", \"0.2ng_rep2\" : \"MokaPot_Output/MsFragger/msf_0.2ng_rep2.csv\", \"0.2ng_rep3\": \"MokaPot_Output/MsFragger/msf_0.2ng_rep3.csv\", \n",
    "                   \"0.2ng_rep4\": \"MokaPot_Output/MsFragger/msf_0.2ng_rep4.csv\", \"0.2ng_rep5\": \"MokaPot_Output/MsFragger/msf_0.2ng_rep5.csv\", \"0.2ng_rep6\": \"MokaPot_Output/MsFragger/msf_0.2ng_rep6.csv\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read in the results from running each tool's data through MokaPot. After we read in all the data we format the data so it can all be read into a large megascript. The dataframes are joined based on their scan number. We then join all of the before and after data together and save the data from each raw file into its own new megascript.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daishavanderwatt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (7,8,55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/Users/daishavanderwatt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3343: DtypeWarning: Columns (19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "../data_loader.py:202: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['temp_peptide'] = df.apply(lambda row: format_oxidation(row, \"Modified sequence\", \"(Oxidation (M))\"), axis=1)\n",
      "../data_loader.py:203: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"temp_peptide\"] = df[\"temp_peptide\"].str[1:-1]\n",
      "../data_loader.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Reverse'] = df['Reverse'].astype(str)\n",
      "../data_loader.py:206: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"decoy\"] = df.apply(lambda row: make_decoy_col_maxquant(row), axis=1)\n",
      "/Users/daishavanderwatt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3343: DtypeWarning: Columns (11,19,20,21,22,23) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/daishavanderwatt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3343: DtypeWarning: Columns (11,19,21,22,23) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/daishavanderwatt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3343: DtypeWarning: Columns (20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/daishavanderwatt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/Users/daishavanderwatt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3343: DtypeWarning: Columns (19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "for file in preMP_data:\n",
    "\n",
    "    msg_df = pd.read_csv(msg_postMP_data[file])\n",
    "    msg_df = msg_df.filter(['ScanNr', 'mokapot score', \"mokapot q-value\"])\n",
    "\n",
    "    mm_df = pd.read_csv(mm_postMP_data[file])\n",
    "    mm_df = mm_df.filter(['ScanNr', 'mokapot score', \"mokapot q-value\"])\n",
    "\n",
    "\n",
    "    msf_df = pd.read_csv(msf_postMP_data[file])\n",
    "    msf_df = msf_df.filter(['ScanNr', 'mokapot score', \"mokapot q-value\"])\n",
    "\n",
    "    mq_df = pd.read_csv(mq_postMP_data[file])\n",
    "    mq_df = mq_df.filter(['ScanNr', 'mokapot score', \"mokapot q-value\"])\n",
    "    \n",
    "    pd_df = get_pd_data(file)\n",
    "\n",
    "    mm_original_df = get_orgininal_mm_data(file)\n",
    "    msf_original_df = get_original_msf_data(file)\n",
    "    msg_original_df = get_original_msg_data(file)\n",
    "    mq_original_df = get_original_mq_data(file)\n",
    "\n",
    "\n",
    "    #Switching index to ScanNr to join dataframes based on their scan numbers. \n",
    "    msg_df = msg_df.set_index('ScanNr')\n",
    "    msg_original_df = msg_original_df.set_index('ScanNr')\n",
    "    msf_df = msf_df.set_index('ScanNr')\n",
    "    msf_original_df = msf_original_df.set_index('ScanNr')\n",
    "    mm_df = mm_df.set_index('ScanNr')\n",
    "    mm_original_df = mm_original_df.set_index('ScanNr')\n",
    "    mq_df = mq_df.set_index('ScanNr')\n",
    "    mq_original_df = mq_original_df.set_index('ScanNr')\n",
    "    pd_df = pd_df.set_index('ScanNr')\n",
    "    \n",
    "\n",
    "    #Joining data from the original and postMokapot into a df for each tool individually\n",
    "    MsFragger = msf_original_df.join(msf_df, how=\"outer\")\n",
    "    MsgfPlus = msg_original_df.join(msg_df, how=\"outer\")\n",
    "    MetaMorpheus = mm_original_df.join(mm_df, how=\"outer\")\n",
    "    MaxQuant = mq_original_df.join(mq_df, how=\"outer\")\n",
    "    \n",
    "    Proteome_Discoverer = pd_df\n",
    "\n",
    "    #combining all the dataframes together into one megaScript\n",
    "    megaScript = pd.concat(dict(MsFragger = MsFragger, MsgfPlus = MsgfPlus, MetaMorpheus = MetaMorpheus, \n",
    "                                MaxQuant = MaxQuant, Proteome_Discoverer = Proteome_Discoverer), axis=1)\n",
    "    megaScript.reset_index(inplace=True)\n",
    "\n",
    "    megaScript.to_csv(\"MegaScript_\" + file + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14796"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df = get_pd_data(\"2ng_rep5\")\n",
    "pd_df = pd_df.set_index('ScanNr')\n",
    "\n",
    "pd_under_cutoff = len(pd_df[pd_df['Percolator q-Value'] <= 0.01])\n",
    "pd_under_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
