{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to test whether adding addition features of the number of max consecutive y peaks and \"perc_in_ladder\"(need to say better) helps MokaPot to score more PSMs at or below a certain cuttoff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mokapot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path\n",
    "import data_loader as dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this function is to clean up the original 'before' data so that we are not counting decoys or duplicate scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df, prob_column):\n",
    "     #drop decoys\n",
    "    df = df[df[\"decoy\"]== False]\n",
    "    #sort by qvalue\n",
    "    df = df.sort_values(prob_column)\n",
    "    #Drop duplicates\n",
    "    df = df.drop_duplicates(subset=[\"scan\"], keep=\"first\") #keep highest scoring\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the before data. It will not be run through MokaPot. It's purpose is to give us the ability to count how many PSMs originally are at or under a specific cutoff and compare that to the number we get after we run the data through MokaPot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PreMokaPot_data(file):\n",
    "    data = dl.clean_metamorph(file)\n",
    "    data = filter_data(data,'QValue')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reads in and cleans the data that will be run through MokaPot. MetaMorphues has a special output file that is formatted to be able to run through MokaPot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_MokaPot(file):\n",
    "    df_2 = dl.get_pin_file(file)\n",
    "    df_2 = df_2.iloc[1: :]\n",
    "    df_2 = df_2.drop_duplicates(subset=[\"ScanNr\"], keep=\"first\")\n",
    "    \n",
    "    return df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gives us back the absolute value of the difference between the predicted retention time from AutoRT and the actual retention time given back from MetaMorpheus. *Must be the absolute value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diff(row):\n",
    "    num = row['y'] - row['y_pred']\n",
    "    if num < 0:\n",
    "        num = num * (-1)\n",
    "    return num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MetaMorpheus gives an output file that is specifically formatted for MokaPot. However, this file does not have q values, which we need to compare the before and after data. However, once the decoys are dropped from both files, the regular before file and the specailly formatted file contain the same scan numbers.\n",
    "The before file is used to compute the number of max consecutive y peaks and \"perc_in_ladder\". These columns are then taken and then added to the specially formatted file. \n",
    "\n",
    "Here we read in the speically formatted file and the file that has the additional feature columns in it. Decoys are dropped from both of them, giving us the same number of scans in both file. We splice out the scan, max_consecutive_y, and \"perc_in_ladder\" columns. These columns are then joined with the formatted file based on their scan numbers. We can use this file to run through MokaPot and compare if the extra feature columns help MokaPot to score more PSMs below our cutoff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peaks_data(pin_df, before_df):\n",
    "\n",
    "    data = pd.read_csv(before_df)\n",
    "    \n",
    "    #Change the ladder column tye to float and changing NAN value to 0 (this will be fixed later)\n",
    "    data['perc_in_ladder'].replace('NAN', \"0\", inplace = True)\n",
    "    data = data.astype({\"perc_in_ladder\": float})\n",
    "    \n",
    "    #sort based on the probability column\n",
    "    data = data.sort_values('probability')\n",
    "    #drop duplicate scans\n",
    "    data = data.drop_duplicates(subset=[\"scan\"], keep=\"first\") #keep highest scoring\n",
    "    \n",
    "    data = data.rename(columns = {\"scan\": \"ScanNr\"})\n",
    "    data = data.filter(['ScanNr', 'max_consecutive_y', \"perc_in_ladder\"])\n",
    "    data = data.set_index(\"ScanNr\")\n",
    "    \n",
    "    #setting up the data from the pin file\n",
    "    df_2 = dl.get_pin_file(pin_df)\n",
    "    df_2 = df_2.iloc[1: :]\n",
    "    df_2 = df_2.astype({\"ScanNr\": int})\n",
    "    df_2 = df_2.drop_duplicates(subset=[\"ScanNr\"], keep=\"first\")\n",
    "    df_2 = df_2.set_index(\"ScanNr\")\n",
    "    \n",
    "    \n",
    "    joined_df = df_2.join(data, how = \"outer\")\n",
    "    joined_df.reset_index(inplace=True)\n",
    "    \n",
    "    return joined_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read in the speically formatted file and the file that has the additional feature columns in it. Decoys are dropped from both of them, giving us the same number of scans in both file. We splice out the scan, and difference columns. These columns are then joined with the formatted file based on their scan numbers. We can use this file to run through MokaPot and compare if the extra feature columns help MokaPot to score more PSMs below our cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retriving and formatting the df that has the retention time info in it. Also doing the math to get \n",
    "#the difference colum\n",
    "\n",
    "def retrive_RT_df(before_df):\n",
    "    \n",
    "    data = pd.read_csv(before_df, sep = \"\\t\")    \n",
    "    \n",
    "    #sort based on the probability column\n",
    "    data = data.sort_values('QValue')\n",
    "    #drop duplicate scans\n",
    "    data = data.drop_duplicates(subset=[\"scan\"], keep=\"first\") #keep highest scoring\n",
    "    #changing the type\n",
    "    data = data.astype({'y_pred': float})\n",
    "    \n",
    "    #calculating the difference column\n",
    "    data['difference'] = data.apply(calculate_diff, axis = 1)\n",
    "    \n",
    "    data = data.rename(columns = {\"scan\": \"ScanNr\"})\n",
    "    data = data.filter(['ScanNr', 'difference'])\n",
    "    data = data.set_index(\"ScanNr\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retentionTime_data(pin_df, before_df):\n",
    "\n",
    "    data = retrive_RT_df(before_df)\n",
    "    \n",
    "    #setting up the data from the pin file\n",
    "    df_2 = dl.get_pin_file(pin_df)\n",
    "    df_2 = df_2.iloc[1: :]\n",
    "    df_2 = df_2.astype({\"ScanNr\": int})\n",
    "    df_2 = df_2.drop_duplicates(subset=[\"ScanNr\"], keep=\"first\")\n",
    "    df_2 = df_2.set_index(\"ScanNr\")\n",
    "    \n",
    "    \n",
    "    joined_df = df_2.join(data, how = \"outer\")\n",
    "    joined_df.reset_index(inplace=True)\n",
    "    \n",
    "    return joined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the dataframe that has the peaks features added on and joining the additional retention time differnce column onto it. Returning the joined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features_data(peaksData, RTdata):\n",
    "    RTdata = RTdata.filter(['ScanNr', 'difference'])\n",
    "    RTdata = RTdata.set_index(\"ScanNr\")\n",
    "    RTdata = RTdata.astype({'difference': float})\n",
    "    \n",
    "    peaksData = peaksData.set_index(\"ScanNr\")\n",
    "    peaksData = peaksData.astype({'perc_in_ladder': float})\n",
    "    \n",
    "    joined_df = peaksData.join(RTdata, how = \"outer\")\n",
    "    joined_df.reset_index(inplace=True)\n",
    "    \n",
    "    return joined_df\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is code that was taken directly from the MokaPot program. It formats the data for the graphs. The purpose of the graphs is to compare the preMokaPot data to the postMokaPot data and compare if we are getting more scans at or below a certain cutoff after running data through MokaPot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_qvalues(qvalues, threshold=0.01, ax=None, **kwargs):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Calculate cumulative targets at each q-value\n",
    "    qvals = pd.Series(qvalues, name=\"qvalue\")\n",
    "    qvals = qvals.sort_values(ascending=True).to_frame()\n",
    "    qvals[\"target\"] = 1\n",
    "    qvals[\"num\"] = qvals[\"target\"].cumsum()\n",
    "    qvals = qvals.groupby([\"qvalue\"]).max().reset_index()\n",
    "    qvals = qvals[[\"qvalue\", \"num\"]]\n",
    "\n",
    "    zero = pd.DataFrame({\"qvalue\": qvals[\"qvalue\"][0], \"num\": 0}, index=[-1])\n",
    "    qvals = pd.concat([zero, qvals], sort=True).reset_index(drop=True)\n",
    "\n",
    "    xmargin = threshold * 0.05\n",
    "    ymax = qvals.num[qvals[\"qvalue\"] <= (threshold + xmargin)].max()\n",
    "    ymargin = ymax * 0.05\n",
    "\n",
    "    # Set margins\n",
    "    curr_ylims = ax.get_ylim()\n",
    "    if curr_ylims[1] < ymax + ymargin:\n",
    "        ax.set_ylim(0 - ymargin, ymax + ymargin)\n",
    "\n",
    "    ax.set_xlim(0 - xmargin, threshold + xmargin)\n",
    "    ax.set_xlabel(\"q-value\")\n",
    "    ax.set_ylabel(f\"Discoveries\")\n",
    "\n",
    "    ax.step(qvals[\"qvalue\"].values, qvals.num.values, where=\"post\", **kwargs)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_qvalues(qvalues, threshold=0.01, ax=None, **kwargs):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Calculate cumulative targets at each q-value\n",
    "    qvals = pd.Series(qvalues, name=\"qvalue\")\n",
    "    qvals = qvals.sort_values(ascending=True).to_frame()\n",
    "    qvals[\"target\"] = 1\n",
    "    qvals[\"num\"] = qvals[\"target\"].cumsum()\n",
    "    qvals = qvals.groupby([\"qvalue\"]).max().reset_index()\n",
    "    qvals = qvals[[\"qvalue\", \"num\"]]\n",
    "\n",
    "    zero = pd.DataFrame({\"qvalue\": qvals[\"qvalue\"][0], \"num\": 0}, index=[-1])\n",
    "    qvals = pd.concat([zero, qvals], sort=True).reset_index(drop=True)\n",
    "\n",
    "    xmargin = threshold * 0.05\n",
    "    ymax = qvals.num[qvals[\"qvalue\"] <= (threshold + xmargin)].max()\n",
    "    ymargin = ymax * 0.05\n",
    "\n",
    "    # Set margins\n",
    "    curr_ylims = ax.get_ylim()\n",
    "    if curr_ylims[1] < ymax + ymargin:\n",
    "        ax.set_ylim(0 - ymargin, ymax + ymargin)\n",
    "\n",
    "    ax.set_xlim(0 - xmargin, threshold + xmargin)\n",
    "    ax.set_xlabel(\"q-value\")\n",
    "    ax.set_ylabel(f\"Discoveries\")\n",
    "\n",
    "    ax.step(qvals[\"qvalue\"].values, qvals.num.values, where=\"post\", **kwargs)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all the files into a list here\n",
    "file_names = [\"2ng_rep1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to tell if the new added features are helping MokaPot to score the PSMs higher, we run the program a certain number of times and look at the average scores.\n",
    "We read in the data for the pin file, the regular data, and the data that has the added features. Because MokaPot gives an output file that is already formatted for MokaPot, we have to splice out the extra columns and joing them with the pin file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daishavanderwatt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3343: DtypeWarning: Columns (19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/daishavanderwatt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (12,22,23,24,75) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/Users/daishavanderwatt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3343: DtypeWarning: Columns (20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "without added feat: 14355\n",
      "with peaks feat: 14654\n",
      "with RT feat: 14792\n",
      "with all added feat: 14812\n",
      "finished round 1\n",
      "without added feat: 14402\n",
      "with peaks feat: 14700\n",
      "with RT feat: 14772\n",
      "with all added feat: 14826\n",
      "finished round 2\n",
      "without added feat: 14445\n",
      "with peaks feat: 14742\n",
      "with RT feat: 14514\n",
      "with all added feat: 14824\n",
      "finished round 3\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "without added feat: 14360\n",
      "with peaks feat: 14726\n",
      "with RT feat: 14786\n",
      "with all added feat: 14532\n",
      "finished round 4\n",
      "without added feat: 14655\n",
      "with peaks feat: 14754\n",
      "with RT feat: 14791\n",
      "with all added feat: 14844\n",
      "finished round 5\n",
      "without added feat: 14561\n",
      "with peaks feat: 14709\n",
      "with RT feat: 14803\n",
      "with all added feat: 14836\n",
      "finished round 6\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "without added feat: 14579\n",
      "with peaks feat: 14691\n",
      "with RT feat: 14787\n",
      "with all added feat: 14854\n",
      "finished round 7\n",
      "without added feat: 14354\n",
      "with peaks feat: 14728\n",
      "with RT feat: 14815\n",
      "with all added feat: 14830\n",
      "finished round 8\n",
      "without added feat: 14385\n",
      "with peaks feat: 14443\n",
      "with RT feat: 14479\n",
      "with all added feat: 14813\n",
      "finished round 9\n",
      "without added feat: 14345\n",
      "with peaks feat: 14768\n",
      "with RT feat: 14486\n",
      "with all added feat: 14812\n",
      "finished round 10\n",
      "without added feat: 14438\n",
      "with peaks feat: 14432\n",
      "with RT feat: 14783\n",
      "with all added feat: 14817\n",
      "finished round 11\n",
      "without added feat: 14632\n",
      "with peaks feat: 14549\n",
      "with RT feat: 14813\n",
      "with all added feat: 14502\n",
      "finished round 12\n",
      "without added feat: 14216\n",
      "with peaks feat: 14718\n",
      "with RT feat: 14802\n",
      "with all added feat: 14808\n",
      "finished round 13\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "without added feat: 14673\n",
      "with peaks feat: 14741\n",
      "with RT feat: 14762\n",
      "with all added feat: 14852\n",
      "finished round 14\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "without added feat: 14361\n",
      "with peaks feat: 14419\n",
      "with RT feat: 14144\n",
      "with all added feat: 14820\n",
      "finished round 15\n",
      "without added feat: 14419\n",
      "with peaks feat: 14575\n",
      "with RT feat: 14797\n",
      "with all added feat: 14509\n",
      "finished round 16\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "without added feat: 14578\n",
      "with peaks feat: 14405\n",
      "with RT feat: 14804\n",
      "with all added feat: 14830\n",
      "finished round 17\n",
      "without added feat: 14406\n",
      "with peaks feat: 14691\n",
      "with RT feat: 14793\n",
      "with all added feat: 14816\n",
      "finished round 18\n",
      "without added feat: 14120\n",
      "with peaks feat: 14703\n",
      "with RT feat: 14783\n",
      "with all added feat: 14516\n",
      "finished round 19\n",
      "without added feat: 14398\n",
      "with peaks feat: 14445\n",
      "with RT feat: 14769\n",
      "with all added feat: 14827\n",
      "finished round 20\n",
      "without added feat: 14405\n",
      "with peaks feat: 14432\n",
      "with RT feat: 14487\n",
      "with all added feat: 14843\n",
      "finished round 21\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "without added feat: 14350\n",
      "with peaks feat: 14678\n",
      "with RT feat: 14819\n",
      "with all added feat: 14777\n",
      "finished round 22\n",
      "without added feat: 14366\n",
      "with peaks feat: 14632\n",
      "with RT feat: 14788\n",
      "with all added feat: 14481\n",
      "finished round 23\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "without added feat: 14105\n",
      "with peaks feat: 14469\n",
      "with RT feat: 14437\n",
      "with all added feat: 14527\n",
      "finished round 24\n",
      "without added feat: 14431\n",
      "with peaks feat: 14731\n",
      "with RT feat: 14810\n",
      "with all added feat: 14847\n",
      "finished round 25\n"
     ]
    }
   ],
   "source": [
    "rounds = 0\n",
    "limit = 25\n",
    "\n",
    "no_addedFeats_list = []\n",
    "peaks_feature_list = []\n",
    "RT_feature_list = []\n",
    "all_features_list = []\n",
    "\n",
    "original_MM = get_PreMokaPot_data('2ng_rep1')\n",
    "regular_df = get_data_for_MokaPot('2ng_rep1')\n",
    "peaks_df = get_peaks_data(\"2ng_rep1\", \"2ng_rep1_new_features.csv\")\n",
    "RT_df = get_retentionTime_data(\"2ng_rep1\", \"test.tsv\")\n",
    "all_feats_df = get_all_features_data(peaks_df, RT_df)\n",
    "\n",
    "\n",
    "while rounds < limit:\n",
    "\n",
    "    mm_for_MP = mokapot.read_pin(regular_df) \n",
    "    regular_results, models = mokapot.brew(mm_for_MP)\n",
    "\n",
    "\n",
    "    mm_peaksFeat_MP = mokapot.read_pin(peaks_df) \n",
    "    peaksAdded_results, added_models = mokapot.brew(mm_peaksFeat_MP)\n",
    "    \n",
    "    mm_RT_feat_MP = mokapot.read_pin(RT_df)\n",
    "    RTadded_results, models = mokapot.brew(mm_RT_feat_MP)\n",
    "    \n",
    "    all_features_MP = mokapot.read_pin(all_feats_df)\n",
    "    allAdded_results, models = mokapot.brew(all_features_MP)\n",
    "\n",
    "      \n",
    "    no_addedFeats_list.append(len(regular_results.psms[regular_results.psms['mokapot q-value'] <= 0.01]))\n",
    "    print(\"without added feat: \" + str(len(regular_results.psms[regular_results.psms['mokapot q-value'] <= 0.01])))\n",
    "    \n",
    "    peaks_feature_list.append(len(peaksAdded_results.psms[peaksAdded_results.psms['mokapot q-value'] <= 0.01]))\n",
    "    print(\"with peaks feat: \" + str(len(peaksAdded_results.psms[peaksAdded_results.psms['mokapot q-value'] <= 0.01])))\n",
    "    \n",
    "    RT_feature_list.append(len(RTadded_results.psms[RTadded_results.psms['mokapot q-value'] <= 0.01]))\n",
    "    print(\"with RT feat: \" + str(len(RTadded_results.psms[RTadded_results.psms['mokapot q-value'] <= 0.01])))\n",
    "    \n",
    "    all_features_list.append(len(allAdded_results.psms[allAdded_results.psms['mokapot q-value'] <= 0.01]))\n",
    "    print(\"with all added feat: \" + str(len(allAdded_results.psms[allAdded_results.psms['mokapot q-value'] <= 0.01])))\n",
    "    \n",
    "    rounds+= 1\n",
    "    print(\"finished round \" + str(rounds))\n",
    "  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores after 25 runs:\n",
      "\tMetaMorpheus native data: 12446\n",
      "\tMetaMorpheus and MokaPot without additional features: \n",
      "\t\tAverage: 14413.56\n",
      "\t\tError: 140.95902383316934\n",
      "\tMetaMorpheus and MokaPot with additional peak features: \n",
      "\t\tAverage: 14621.4\n",
      "\t\tError: 126.3727818796437\n",
      "\tMetaMorpheus and MokaPot with additional RT difference features: \n",
      "\t\tAverage: 14704.64\n",
      "\t\tError: 169.88605122257684\n",
      "\tMetaMorpheus and MokaPot with all additional features: \n",
      "\t\tAverage: 14750.2\n",
      "\t\tError: 135.49022104934363\n"
     ]
    }
   ],
   "source": [
    "def get_avg(num_list):\n",
    "    total = 0\n",
    "    for num in num_list:\n",
    "        total = total + num\n",
    "    avg = total/len(num_list)\n",
    "    return avg\n",
    "\n",
    "   \n",
    "print(\"Average scores after 25 runs:\")  \n",
    "\n",
    "print(\"\\t\" + \"MetaMorpheus native data: \" + str(len((original_MM[original_MM['QValue'] <= 0.01]))))\n",
    "\n",
    "print(\"\\t\" + \"MetaMorpheus and MokaPot without additional features: \")\n",
    "print(\"\\t\\t\" + \"Average: \" + str(np.mean(no_addedFeats_list)))\n",
    "print(\"\\t\\t\" + \"Error: \" + str(np.std(no_addedFeats_list)))\n",
    "\n",
    "print(\"\\t\" + \"MetaMorpheus and MokaPot with additional peak features: \")\n",
    "print(\"\\t\\t\" + \"Average: \" + str(np.mean(peaks_feature_list)))\n",
    "print(\"\\t\\t\" + \"Error: \" + str(np.std(peaks_feature_list)))\n",
    "\n",
    "print(\"\\t\" + \"MetaMorpheus and MokaPot with additional RT difference features: \" )\n",
    "print(\"\\t\\t\" + \"Average: \" + str(np.mean(RT_feature_list)))\n",
    "print(\"\\t\\t\" + \"Error: \" + str(np.std(RT_feature_list)))\n",
    "\n",
    "print(\"\\t\" + \"MetaMorpheus and MokaPot with all additional features: \")\n",
    "print(\"\\t\\t\" + \"Average: \" + str(np.mean(all_features_list)))\n",
    "print(\"\\t\\t\" + \"Error: \" + str(np.std(all_features_list)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the graph for the average number of PSMs at or under a 0.01 cutoff. Standard deviation is given as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No Features</th>\n",
       "      <th>All Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14355</td>\n",
       "      <td>14812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14402</td>\n",
       "      <td>14826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14445</td>\n",
       "      <td>14824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14360</td>\n",
       "      <td>14532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14655</td>\n",
       "      <td>14844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14561</td>\n",
       "      <td>14836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14579</td>\n",
       "      <td>14854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14354</td>\n",
       "      <td>14830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14385</td>\n",
       "      <td>14813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14345</td>\n",
       "      <td>14812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14438</td>\n",
       "      <td>14817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14632</td>\n",
       "      <td>14502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14216</td>\n",
       "      <td>14808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14673</td>\n",
       "      <td>14852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14361</td>\n",
       "      <td>14820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14419</td>\n",
       "      <td>14509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14578</td>\n",
       "      <td>14830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14406</td>\n",
       "      <td>14816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14120</td>\n",
       "      <td>14516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14398</td>\n",
       "      <td>14827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14405</td>\n",
       "      <td>14843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14350</td>\n",
       "      <td>14777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>14366</td>\n",
       "      <td>14481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14105</td>\n",
       "      <td>14527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14431</td>\n",
       "      <td>14847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    No Features  All Features\n",
       "0         14355         14812\n",
       "1         14402         14826\n",
       "2         14445         14824\n",
       "3         14360         14532\n",
       "4         14655         14844\n",
       "5         14561         14836\n",
       "6         14579         14854\n",
       "7         14354         14830\n",
       "8         14385         14813\n",
       "9         14345         14812\n",
       "10        14438         14817\n",
       "11        14632         14502\n",
       "12        14216         14808\n",
       "13        14673         14852\n",
       "14        14361         14820\n",
       "15        14419         14509\n",
       "16        14578         14830\n",
       "17        14406         14816\n",
       "18        14120         14516\n",
       "19        14398         14827\n",
       "20        14405         14843\n",
       "21        14350         14777\n",
       "22        14366         14481\n",
       "23        14105         14527\n",
       "24        14431         14847"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(no_addedFeats_list, all_features_list)),\n",
    "               columns =['No Features', 'All Features'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9e-11\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "t_test = stats.ttest_ind(df[\"No Features\"], df[\"All Features\"])\n",
    "pval = t_test.pvalue\n",
    "\n",
    "formatted_string = \"{:.12f}\".format(pval)\n",
    "pvalue = float(formatted_string)\n",
    "\n",
    "print(pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "features_plot = sns.boxplot(data=df, showfliers=False)\n",
    "features_plot = sns.stripplot(data=df, jitter=True, color=\".3\")\n",
    "features_plot.set(ylabel = \"Number of PSMs per scan\")\n",
    "features_plot.set(xlabel = \"Presence of Features\")\n",
    "\n",
    "\n",
    "#statistical annotation\n",
    "x1, x2 = 0, 1   # columns 'Sat' and 'Sun' (first column: 0, see plt.xticks())\n",
    "y, h, col = df['All Features'].max() + 50, 2, 'k'\n",
    "plt.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "plt.text((x1+x2)*.5, y+h, \"t-test pvalue = \" + str(pvalue), ha='center', va='bottom', color=col)\n",
    "\n",
    "figure3 = plt.gcf()\n",
    "figure3.savefig('features_graph', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#put the pvalue in the legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
