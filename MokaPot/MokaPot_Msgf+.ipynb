{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mokapot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path\n",
    "import data_loader as dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this function is to clean up the original 'before' data so that we are not counting decoys or duplicate scans. Mokapot needs the decoys, so they are only removed from the 'before' data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df, prob_column='QValue'):\n",
    "    #drop decoy\n",
    "    df = df[df[\"decoy\"]==False]\n",
    "    #sort by qvalue\n",
    "    df = df.sort_values(prob_column)\n",
    "    #drop duplicate scans\n",
    "    df = df.drop_duplicates(subset=[\"scan\"], keep=\"first\") #keep highest coring\n",
    " \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MokaPot needs a column in a specific format that notates whether a scan was decoy or not. The \"make_decoy_col_msgf\" function generates that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decoy_col_msgf(row):\n",
    "    if row[\"Protein\"].startswith(\"XXX_\"):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us back the \"before\" dataset. We will clean the data by dropping duplicates and decoys. The purpose of this is to be able to count how many scans we originally have at or under a specific cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PreMokaPot_data(file):\n",
    "    msg_cleaned_df = dl.clean_msgfplus(file)\n",
    "    msg_cleaned_df = filter_data(msg_cleaned_df)\n",
    "    return msg_cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read in the data and clean it up before we run it thorugh MokaPot. We drop any duplicate scans before the data is fed into MokaPot. We also change the scan number name so that all of our files will match in the end so we can merge them into one megascript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the data and formatting it for MokaPot\n",
    "def get_data_for_MokaPot(file):\n",
    "    msg_df = dl.clean_msgfplus(file)\n",
    "    \n",
    "    #adding target colum for MokaPot\n",
    "    msg_df[\"target_column\"] = msg_df.apply(make_decoy_col_msgf, axis = 1)\n",
    "    \n",
    "    #sort by qvalue and drop duplicate scans\n",
    "    msg_df = msg_df.sort_values('QValue')\n",
    "    msg_df = msg_df.drop_duplicates(subset=[\"scan\"], keep=\"first\") #keep highest scoring\n",
    "    \n",
    "    msg_df = msg_df.rename(columns = {\"scan\": \"ScanNr\"})\n",
    "    \n",
    "    return msg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we run each input file through MokaPot. Each file we read in is analyzed and the results are saved in a seperate output file.\n",
    "MokaPot requires feature columns that it uses to give each scan a new q value score. The columns from Msgf+ that we have chosen to use as features are: 'IsotopeError', 'PrecursorError(ppm)', 'DeNovoScore', 'MSGFScore', and 'SpecEValue'. 'Charge' is also used as a one hot encoding per the recommendation of the writer of MokaPot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all the files into a list here\n",
    "file_names = [\"2ng_rep1\", \"2ng_rep2\", \"2ng_rep3\", \"2ng_rep4\", \"2ng_rep5\", \"2ng_rep6\",\n",
    "             \"0.2ng_rep1\", \"0.2ng_rep2\", \"0.2ng_rep3\", \"0.2ng_rep4\", \"0.2ng_rep5\", \"0.2ng_rep6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Learned model did not improve over the best feature. Now scoring by the best feature for each collection of PSMs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "The number of PSMs found at or above 0.01 for 2ng_rep1:\n",
      "\tMSGF+: 12014\n",
      "\tMSGF+ and MokaPot: 11931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Learned model did not improve over the best feature. Now scoring by the best feature for each collection of PSMs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PSMs found at or above 0.01 for 2ng_rep2:\n",
      "\tMSGF+: 11808\n",
      "\tMSGF+ and MokaPot: 11727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Learned model did not improve over the best feature. Now scoring by the best feature for each collection of PSMs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PSMs found at or above 0.01 for 2ng_rep3:\n",
      "\tMSGF+: 9684\n",
      "\tMSGF+ and MokaPot: 9580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Learned model did not improve over the best feature. Now scoring by the best feature for each collection of PSMs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PSMs found at or above 0.01 for 2ng_rep4:\n",
      "\tMSGF+: 9513\n",
      "\tMSGF+ and MokaPot: 9421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Learned model did not improve over the best feature. Now scoring by the best feature for each collection of PSMs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PSMs found at or above 0.01 for 2ng_rep5:\n",
      "\tMSGF+: 14406\n",
      "\tMSGF+ and MokaPot: 14314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Learned model did not improve over the best feature. Now scoring by the best feature for each collection of PSMs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PSMs found at or above 0.01 for 2ng_rep6:\n",
      "\tMSGF+: 13520\n",
      "\tMSGF+ and MokaPot: 13392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Learned model did not improve over the best feature. Now scoring by the best feature for each collection of PSMs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PSMs found at or above 0.01 for 0.2ng_rep1:\n",
      "\tMSGF+: 6322\n",
      "\tMSGF+ and MokaPot: 6261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Learned model did not improve over the best feature. Now scoring by the best feature for each collection of PSMs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "The number of PSMs found at or above 0.01 for 0.2ng_rep2:\n",
      "\tMSGF+: 6305\n",
      "\tMSGF+ and MokaPot: 6249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Learned model did not improve over the best feature. Now scoring by the best feature for each collection of PSMs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: IRLS did not converge with maxIter = 50\n",
      "The number of PSMs found at or above 0.01 for 0.2ng_rep3:\n",
      "\tMSGF+: 4505\n",
      "\tMSGF+ and MokaPot: 4442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Learned model did not improve over the best feature. Now scoring by the best feature for each collection of PSMs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "Warning: IRLS did not converge with maxIter = 50\n",
      "The number of PSMs found at or above 0.01 for 0.2ng_rep4:\n",
      "\tMSGF+: 4268\n",
      "\tMSGF+ and MokaPot: 4221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Learned model did not improve over the best feature. Now scoring by the best feature for each collection of PSMs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PSMs found at or above 0.01 for 0.2ng_rep5:\n",
      "\tMSGF+: 4887\n",
      "\tMSGF+ and MokaPot: 4839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Learned model did not improve over the best feature. Now scoring by the best feature for each collection of PSMs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PSMs found at or above 0.01 for 0.2ng_rep6:\n",
      "\tMSGF+: 4387\n",
      "\tMSGF+ and MokaPot: 4345\n"
     ]
    }
   ],
   "source": [
    "for file in file_names:\n",
    "    msg_cleaned_df = get_PreMokaPot_data(file)\n",
    "    msg_df = get_data_for_MokaPot(file)\n",
    "\n",
    "    charge_feat = pd.get_dummies(msg_df[\"Charge\"], prefix=\"Charge\")\n",
    "    msg_df = pd.concat([msg_df, charge_feat], axis=1)\n",
    "\n",
    "    msg_for_MP = mokapot.dataset.LinearPsmDataset(msg_df, target_column = \"target_column\", spectrum_columns = \"ScanNr\",\n",
    "                                            peptide_column = \"peptide\", protein_column=None, \n",
    "                                            group_column=None, feature_columns= (list(charge_feat.columns) + [\"IsotopeError\",  \n",
    "                                            \"PrecursorError(ppm)\", \"DeNovoScore\",\"MSGFScore\",\"SpecEValue\"]), copy_data=True)\n",
    "    \n",
    "    results, models = mokapot.brew(msg_for_MP)\n",
    "    \n",
    "    results_df = results.psms\n",
    "    results_df.to_csv(\"MokaPot_Output/MsgfPlus/msg_\" + file + \".csv\")\n",
    "    \n",
    "    print(\"The number of PSMs found at or above 0.01 for \" + file + \":\")   \n",
    "    print(\"\\t\" + \"MSGF+: \" + str(len(msg_df[msg_df['QValue'] <= 0.01])))\n",
    "    print(\"\\t\"\"MSGF+ and MokaPot: \" + str(len(results.psms[results.psms['mokapot q-value'] <= 0.01])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
