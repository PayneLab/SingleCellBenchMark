{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mokapot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path\n",
    "import data_loader as dl\n",
    "import megascript_loader as ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making our Figure with Your Data - a tutorial\n",
    "\n",
    "This notebook describes how you can compare data from an algorithm to output for algorithms that have been previously benchmarked. \n",
    "\n",
    "In order to compare your program's output to our benchmarked data, you will need to run the same raw files  through your algorithm. Begin by downloading six 2ng and six 0.2ng files from MassIVE (MSV000087689). Run these through your program and save the files in a .csv format. \n",
    "\n",
    "To accuratly run your files against ours, each file will need to have a \"scan\", \"decoy\", \"peptide\", and some type of probability column.\n",
    "- \"scan\" is the scan number column . \n",
    "- \"decoy\" is a boolean column that tracks whether a scan was tagged as a decoy or not. True denotes a decoy.\n",
    "- \"peptide\" is the column that has a string with the peptide found for each scan\n",
    "- The probability column presents the score/confidence that the tool gave to a specific scan. If your tool has a  qvalue or PEP value column, use this. All of the benchmarked data's probability column are scored on a scale where 0 is the best and 1 is the worst. You will want your data's probability column to be scaled this way as well. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Defining Your Variables\n",
    "\n",
    "The first thing that you have to do is to tell us where your data lives, and then we can get about parsing it and working to make the figure. Once you have ran the raw files and saved the correctly formatted output files, insert the file paths into the correct spot in the input_files list below. Make sure that the right file is loaded into the right spot or your tool's output will not be correctly compared to the benchmarked data.\n",
    "\n",
    "We will also ask you to type in the name of your probability column and the name of your tool.\n",
    "\n",
    "Afterwards, we will take your data paths and put them into a list. This will make it easier for us to parse your data and make sure each file is compared to the right benchmarked files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#please fill in the actual file paths to each of these output files on your computer. Each of these files are\n",
    "#the names of the raw files from MassIVE that you would have ran through your tool.\n",
    "\n",
    "Ex_Auto_J3_30umTB_2ngQC_60m_1 = \"/path/to/your/file.txt\"\n",
    "Ex_Auto_J3_30umTB_2ngQC_60m_2 = \"/path/to/your/file.txt\"\n",
    "Ex_Auto_K13_30umTA_2ngQC_60m_1 = \"/path/to/your/file.txt\"\n",
    "Ex_Auto_K13_30umTA_2ngQC_60m_2 = \"/path/to/your/file.txt\"\n",
    "Ex_Auto_W17_30umTA_2ngQC_60m_3 = \"/path/to/your/file.txt\"\n",
    "Ex_Auto_W17_30umTA_2ngQC_60m_4 = \"/path/to/your/file.txt\"\n",
    "\n",
    "Ex_Auto_J3_30umTB_02ngQC_60m_1 = \"/path/to/your/file.txt\"\n",
    "Ex_Auto_J3_30umTB_02ngQC_60m_2 = \"/path/to/your/file.txt\"\n",
    "Ex_Auto_K13_30umTA_02ngQC_60m_1 = \"/path/to/your/file.txt\"\n",
    "Ex_Auto_K13_30umTA_02ngQC_60m_2 = \"/path/to/your/file.txt\"\n",
    "Ex_Auto_W17_30umTA_02ngQC_60m_3 = \"/path/to/your/file.txt\"\n",
    "Ex_Auto_W17_30umTA_02ngQC_60m_4 = \"/path/to/your/file.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Type in the name of your probability column and your tool. Afterwards, run the cell. \n",
    "\n",
    "probability_column = \"put your probabiliy column name here\" \n",
    "tool_name = \"type the name of your tool\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are simply storing your file paths into a dictionary. This will help us to make sure we compare\n",
    "#your data to the correctly benchmarked files. There is nothing you need to edit here. Simply run the cell.\n",
    "\n",
    "input_files = {} \n",
    "    #2ng files\n",
    "input_files[\"2ng_rep1\"] = Ex_Auto_J3_30umTB_2ngQC_60m_1\n",
    "input_files[\"2ng_rep2\"] = Ex_Auto_J3_30umTB_2ngQC_60m_2\n",
    "input_files[\"2ng_rep3\"] = Ex_Auto_K13_30umTA_2ngQC_60m_1\n",
    "input_files[\"2ng_rep4\"] = Ex_Auto_K13_30umTA_2ngQC_60m_2\n",
    "input_files[\"2ng_rep5\"] = Ex_Auto_W17_30umTA_2ngQC_60m_3\n",
    "input_files[\"2ng_rep6\"] = Ex_Auto_W17_30umTA_2ngQC_60m_4\n",
    "\n",
    "    #0.2ng files\n",
    "input_files[\"0.2ng_rep1\"] = Ex_Auto_J3_30umTB_02ngQC_60m_1\n",
    "input_files[\"0.2ng_rep2\"] = Ex_Auto_J3_30umTB_02ngQC_60m_2\n",
    "input_files[\"0.2ng_rep3\"] = Ex_Auto_K13_30umTA_02ngQC_60m_1\n",
    "input_files[\"0.2ng_rep4\"] = Ex_Auto_K13_30umTA_02ngQC_60m_2\n",
    "input_files[\"0.2ng_rep5\"] = Ex_Auto_W17_30umTA_02ngQC_60m_3\n",
    "input_files[\"0.2ng_rep6\"] = Ex_Auto_W17_30umTA_02ngQC_60m_4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Parse Your Data Into A Dataframe. \n",
    "\n",
    "Below we are going to take your input files and get them into a data frames. Each dataframe that we make will be saved. \n",
    "\n",
    "Our filter function will drop any scans that have been flagged as decoys. We will also ensure that you do not have any duplicate scan numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /path/to/your/file.txt does not exist: '/path/to/your/file.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8283a83ca105>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#No changes need to be made here. Please just run the cell.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mformatted_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Payne_Lab/SingleCellBenchMark/Living_BenchMarking/megascript_loader.py\u001b[0m in \u001b[0;36mfilter_input\u001b[0;34m(input_files, probability)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m          \u001b[0;31m# make sure decoy column is a boolean column and then drop decoys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /path/to/your/file.txt does not exist: '/path/to/your/file.txt'"
     ]
    }
   ],
   "source": [
    "#No changes need to be made here. Please just run the cell. \n",
    "\n",
    "formatted_files = ml.filter_input(input_files, probability_column) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's just look at one of your dfs/tables to make sure everying parsed correctly.\n",
    "You should have a scan and a peptide column as well as the column that you chose for the probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#No need to change anything, simply run the cell to view one of your dataframes.\n",
    "\n",
    "formatted_files[\"2ng_rep1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Make the MegaScript\n",
    "For each raw file, we will join your output with our output data into a megascript. This will allow you to see what your tools scans are finding relative to the tools that we benchamarked.\n",
    "To make the megascripts we will first read in our output for a specific raw file. We will then take our output and join your data to make the megascript. \n",
    "\n",
    "Each of the megascript will be saved as \"benchmark_MegaScript_\" + file name + \".csv\". The file name correlates to the name of the raw files. For example, if you want to look at all the data that came from the Ex_Auto_J3_30umTB_2ngQC_60m_1 file, we can view that megascript by reading in the \"benchmark_MegaScript_Ex_Auto_J3_30umTB_2ngQC_60m_1.csv\" file.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#You do not need to input anything. Run the cell to make all your megascripts. \n",
    "\n",
    "ml.make_megascript(formatted_files, tool_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at one of our final megascripts. You will see that there are 2 levels of heading for our megascript. We can see the probability and peptide that was found for each algorithm at a scan number. At scans where the algorithm did have an output for that scan number, the table will simply have \"Nan\". There will be spots where some tools do not have values and others did. \n",
    "\n",
    "Note: when saving a multiindexed dataframe to a .csv file, the format is not fully saved. We have to do some formatting to get it to look the way it was originally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formatting the megascript after it is read in from the csv.\n",
    "#Running this cell will take care of all the formatting; you do not need to change anything. \n",
    "\n",
    "df = pd.read_csv(\"benchmark_MegaScript_Ex_Auto_J3_30umTB_2ngQC_60m_1.csv\", header=[0,1])\n",
    "df = df.drop(\"Unnamed: 0_level_0\", axis = 1, level = 0)\n",
    "df = df.rename(columns={'Unnamed: 1_level_1': \" \"})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Make the Graphs\n",
    "We will now make the graphs that will show us how many PSMs at or below our 1% FDR cutoff each tool is finding for the relative raw files. We will make one graph for all the 2ng files and another for all the 0.2ng files. \n",
    "\n",
    "The graphs will save to your computer as '2ng_native_score.png' and '0.2ng_native_score.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell makes the 2ng graph. Please just run this cell, there is no need to change anything.\n",
    "\n",
    "ml.make_2ng_graph(probability_column, tool_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell makes the 0.2ng graph. Please just run this cell, there is no need to change anything.\n",
    "\n",
    "ml.make_02ng_graph(probability_column, tool_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
