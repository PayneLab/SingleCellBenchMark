{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mokapot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path\n",
    "import data_loader as dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes the 'before' data and filters it by dropping decoys and duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df, prob_column):\n",
    "    #drop decoys\n",
    "    df = df[df[\"decoy\"]==False]\n",
    "    #sort by qvalue\n",
    "    df = df.sort_values(prob_column)\n",
    "    #drop duplicate scans\n",
    "    df = df.drop_duplicates(subset=[\"scan\"], keep=\"first\") #keep highest scoring\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in all of our data from the parser and formatting it to be combined in a megascript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in and formatting the original MetaMorpheus data\n",
    "def get_orgininal_mm_data(file):\n",
    "    mm_original_df = dl.clean_metamorph(file)\n",
    "    mm_original_df = filter_data( mm_original_df, \"QValue\")\n",
    "    \n",
    "    #filter out just the ScanNr and QValue and/or PEP columns\n",
    "    mm_original_df = mm_original_df.filter(items = ['scan', 'peptide', 'QValue', 'PEP'])\n",
    "    \n",
    "    return mm_original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in and formatting the orginial MsFragger data\n",
    "def set_probablility(row):\n",
    "    new_prob = 1 - row[\"PeptideProphet Probability\"]\n",
    "    return new_prob\n",
    "\n",
    "#pulling only scan numbers out\n",
    "def extractScanNum(row):\n",
    "    string = row\n",
    "    spot = string.find('.')\n",
    "    new_st = string[spot + 1:]\n",
    "    spot = new_st.find('.')\n",
    "    final_st = new_st[:spot]\n",
    "    \n",
    "    if final_st[0] == \"0\":\n",
    "        final_st = final_st[1:]\n",
    "    return final_st\n",
    "\n",
    "def get_original_msf_data(file):\n",
    "    msf_original_df = dl.clean_msfragger(file)\n",
    "    \n",
    "    #Extracting scan number from file number\n",
    "    msf_original_df['scan'] =msf_original_df['scan'].apply(extractScanNum) \n",
    "    \n",
    "    msf_original_df = filter_data(msf_original_df, 'PeptideProphet Probability')\n",
    "    \n",
    "    #Changing the probabilities to the same scale all the other tools use \n",
    "    msf_original_df[\"Updated_probability\"] =  msf_original_df.apply(set_probablility, 1)\n",
    "    \n",
    "    #filter out just the ScanNr and QValue and/or PEP columns\n",
    "    msf_original_df = msf_original_df.filter(['scan', 'peptide','Updated_probability'])\n",
    "    \n",
    "    return  msf_original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in and formatting the orginial MsgfPlus data\n",
    "def get_original_msg_data(file):\n",
    "    msg_original_df = dl.clean_msgfplus(file)\n",
    "    msg_original_df = filter_data(msg_original_df, \"QValue\")\n",
    "    \n",
    "    #filter out just the ScanNr and QValue and/or PEP columns\n",
    "    msg_original_df = msg_original_df.filter(['scan', 'peptide', \"QValue\"])\n",
    "    \n",
    "    return msg_original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in and formatting the orginial MaxQuant data\n",
    "def get_original_mq_data(file):\n",
    "     mq_original_df =  dl.clean_maxquant(file)\n",
    "    \n",
    "#Formatting and dropping any rows that are missing the sequence\n",
    "     mq_original_df['Sequence'].replace(' ', np.nan, inplace = True)\n",
    "     mq_original_df.dropna(subset=['Sequence'], inplace=True)\n",
    "    \n",
    "     mq_original_df = filter_data(mq_original_df, 'PEP')\n",
    "    \n",
    "    #filter out the ScanNr, peptide, and PEP columns\n",
    "     mq_original_df = mq_original_df.filter(['scan', 'peptide', 'PEP'])\n",
    "    \n",
    "     return  mq_original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in and formatting the data to be compared to the benchmarked data\n",
    "def get_input_data(file, probability):\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    #These need to come out, for testing only with the data I have \n",
    "    df['decoy'].replace('False', False, inplace = True) \n",
    "    df['decoy'].replace('True', True, inplace = True)\n",
    "    \n",
    "    df = filter_data(df, probability)\n",
    "    \n",
    "    #filter out the ScanNr, peptide, and probability columns\n",
    "    df = df.filter(['scan', probability])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will read in the megascript that contains the output data from a single raw file that was ran through each tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the megaScript and reformat it\n",
    "def clean_meagScript(file):\n",
    "    df = pd.read_csv(file, low_memory=False,  header=[0,1])\n",
    "    df.drop(columns = {\"Unnamed: 0_level_0\"})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing out the Peptide Prophet Probability values for MsFragger. There is no qvalue or PEP, so this is the row we are using. \n",
    "Counting how many are at or under the cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msf_prob_len(df, cutoff):\n",
    "    msf_probability = df[\"MsFragger\"]['Updated_probability']\n",
    "    msf_probability =  msf_probability.dropna()\n",
    "    msf_under_cutoff = len(msf_probability.loc[msf_probability <= cutoff])\n",
    "    return msf_under_cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing out the qvalues from MetaMorpheus and counting how many are at or under the cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mm_Qval_len(df, cutoff):\n",
    "    mm_qval = df[\"MetaMorpheus\"][\"QValue\"] \n",
    "    mm_qval =  mm_qval.dropna() \n",
    "    mm_under_cutoff = len(mm_qval.loc[mm_qval <= cutoff])\n",
    "    return mm_under_cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing out the PEP values from MetaMorpheus and counting how many are at or under the cutoff\n",
    "**Are we keeping this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mm_PEP_len(df, cutoff):\n",
    "    mm_PEP = df[\"MetaMorpheus\"][\"PEP\"] \n",
    "    mm_PEP =  mm_PEP.dropna() \n",
    "    value_under_cutoff = len(mm_PEP.loc[mm_PEP <= cutoff])\n",
    "    return value_under_cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing out the qvalues from MsgfPlus and counting how many are at or under the cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msg_Qval_len(df, cutoff):\n",
    "    msg_qval = df[\"MsgfPlus\"][\"QValue\"] \n",
    "    msg_qval =  msg_qval.dropna() \n",
    "    msg_under_cutoff = len(msg_qval.loc[msg_qval <= cutoff])\n",
    "    return msg_under_cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing out the PEP from MaxQuant. Counting how many are at or under the cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mq_PEP_len(df, cutoff):\n",
    "    mq_PEP = df[\"MaxQuant\"][\"PEP\"] \n",
    "    mq_PEP =  mq_PEP.dropna() \n",
    "    mq_under_cutoff = len(mq_PEP.loc[mq_PEP <= cutoff])\n",
    "    return mq_under_cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing out the probability column from the inputted data and counting how many scans are at or under the cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_len(df, cutoff, probability):\n",
    "    df = df[\"InputData\"][probability] \n",
    "    df =  df.dropna() \n",
    "    df_under_cutoff = len(df.loc[df <= cutoff])\n",
    "    return df_under_cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gets the number of scan values that were at or below the cutoff for each tool and returns them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_values(file, cutoff, inputs_probability):\n",
    "    df = clean_meagScript(file)\n",
    "    msf = get_msf_prob_len(df, cutoff)\n",
    "    MM_QVal = get_mm_Qval_len(df, cutoff)\n",
    "    MM_PEP = get_mm_PEP_len(df, cutoff)\n",
    "    msg_QVal = get_msg_Qval_len(df, cutoff)\n",
    "    MQ_PEP = get_mq_PEP_len(df, cutoff)\n",
    "    input_data = get_input_len(df, cutoff, inputs_probability)\n",
    "    values_list = {\"msf\" : msf, \"MM_QVal\" : MM_QVal, \"MM_PEP\" : MM_PEP, \"msg_QVal\" : msg_QVal, \"MQ_PEP\" : MQ_PEP, \"input_data\": input_data}\n",
    "    return values_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the data and making the graph for the 2ng data at a certain cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_2ng_graph(cutoff, input_probability):\n",
    "    File1 = get_file_values(\"benchmark_MegaScript_2ng_rep1.csv\", cutoff, input_probability)\n",
    "    File2 = get_file_values(\"benchmark_MegaScript_2ng_rep2.csv\", cutoff, input_probability)\n",
    "    File3 = get_file_values(\"benchmark_MegaScript_2ng_rep3.csv\", cutoff, input_probability)\n",
    "    File4 = get_file_values(\"benchmark_MegaScript_2ng_rep4.csv\", cutoff, input_probability)\n",
    "    File5 = get_file_values(\"benchmark_MegaScript_2ng_rep5.csv\", cutoff, input_probability)\n",
    "    File6 = get_file_values(\"benchmark_MegaScript_2ng_rep6.csv\", cutoff, input_probability)\n",
    "\n",
    "    # set width of bars\n",
    "    barWidth = 0.14\n",
    "\n",
    "    # set heights of bars\n",
    "    msf_prob = [File1['msf'], File2['msf'], File3['msf'], File4['msf'], File5['msf'], File6['msf']]\n",
    "    MM_PEP = [File1['MM_PEP'], File2['MM_PEP'], File3['MM_PEP'], File4['MM_PEP'], File5['MM_PEP'], File6['MM_PEP']]\n",
    "    MM_qval = [File1['MM_QVal'], File2['MM_QVal'], File3['MM_QVal'], File4['MM_QVal'], File5['MM_QVal'], File6['MM_QVal']]\n",
    "    msg_qval = [File1['msg_QVal'], File2['msg_QVal'], File3['msg_QVal'], File4['msg_QVal'], File5['msg_QVal'], File6['msg_QVal']]\n",
    "    mq_PEP = [File1['MQ_PEP'], File2['MQ_PEP'], File3['MQ_PEP'], File4['MQ_PEP'], File5['MQ_PEP'], File6['MQ_PEP']]\n",
    "    input_prob = [File1['input_data'], File2['input_data'], File3['input_data'], File4['input_data'], File5['input_data'], File6['input_data']]\n",
    "    \n",
    "    # Set position of bar on X axis\n",
    "    r1 = np.arange(len(msf_prob))\n",
    "    r2 = [x + barWidth for x in r1]\n",
    "    r3 = [x + barWidth for x in r2]\n",
    "    r4 = [x + barWidth for x in r3]\n",
    "    r5 = [x + barWidth for x in r4]\n",
    "    r6 = [x + barWidth for x in r5]\n",
    "\n",
    "    # Make the plot\n",
    "    plt.bar(r1, msf_prob, width=barWidth, edgecolor='white', label='MsFragger Peptide Prophet Probability')\n",
    "    plt.bar(r2, MM_qval, width=barWidth, edgecolor='white', label='MetaMorpheus Q-Value')\n",
    "    plt.bar(r3, msg_qval, width=barWidth, edgecolor='white', label='MsgfPlus Q-Value')\n",
    "    plt.bar(r4, mq_PEP, width=barWidth, edgecolor='white', label='MaxQuant PEP')\n",
    "    plt.bar(r5, MM_PEP, width=barWidth, edgecolor='white', label='MetaMorpheus PEP')\n",
    "    plt.bar(r6, input_prob, width=barWidth, edgecolor='white', label='Input ' + input_probability)\n",
    "\n",
    "    # Add xticks on the middle of the group bars\n",
    "    plt.ylabel('#PSMs')\n",
    "    plt.xlabel('# PSMs using native score and cutoff')\n",
    "    plt.title('2ng')\n",
    "    plt.xticks([r + barWidth for r in range(len(msf_prob))], ['File1', 'File2', 'File3', 'File4', 'File5', 'File6'])\n",
    "\n",
    "    # Create legend & Show graph\n",
    "    plt.legend(loc = \"upper right\", bbox_to_anchor=(1.73, 1))\n",
    "    plt.show()\n",
    "    #plt.savefig('2ng_PSM_native_score.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the data and making the graph for the 0.2ng data at a certain cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_02ng_graph(cutoff, input_probability):\n",
    "    File1 = get_file_values(\"benchmark_MegaScript_0.2ng_rep1.csv\", cutoff, input_probability)\n",
    "    File2 = get_file_values(\"benchmark_MegaScript_0.2ng_rep2.csv\", cutoff, input_probability)\n",
    "    File3 = get_file_values(\"benchmark_MegaScript_0.2ng_rep3.csv\", cutoff, input_probability)\n",
    "    File4 = get_file_values(\"benchmark_MegaScript_0.2ng_rep4.csv\", cutoff, input_probability)\n",
    "    File5 = get_file_values(\"benchmark_MegaScript_0.2ng_rep5.csv\", cutoff, input_probability)\n",
    "    File6 = get_file_values(\"benchmark_MegaScript_0.2ng_rep6.csv\", cutoff, input_probability)\n",
    "\n",
    "\n",
    "    # set width of bars\n",
    "    barWidth = 0.14\n",
    "\n",
    "    # set heights of bars\n",
    "    msf_prob = [File1['msf'], File2['msf'], File3['msf'], File4['msf'], File5['msf'], File6['msf']]\n",
    "    MM_PEP = [File1['MM_PEP'], File2['MM_PEP'], File3['MM_PEP'], File4['MM_PEP'], File5['MM_PEP'], File6['MM_PEP']]\n",
    "    MM_qval = [File1['MM_QVal'], File2['MM_QVal'], File3['MM_QVal'], File4['MM_QVal'], File5['MM_QVal'], File6['MM_QVal']]\n",
    "    msg_qval = [File1['msg_QVal'], File2['msg_QVal'], File3['msg_QVal'], File4['msg_QVal'], File5['msg_QVal'], File6['msg_QVal']]\n",
    "    mq_PEP = [File1['MQ_PEP'], File2['MQ_PEP'], File3['MQ_PEP'], File4['MQ_PEP'], File5['MQ_PEP'], File6['MQ_PEP']]\n",
    "    input_prob = [File1['input_data'], File2['input_data'], File3['input_data'], File4['input_data'], File5['input_data'], File6['input_data']]\n",
    "    \n",
    "    # Set position of bar on X axis\n",
    "    r1 = np.arange(len(msf_prob))\n",
    "    r2 = [x + barWidth for x in r1]\n",
    "    r3 = [x + barWidth for x in r2]\n",
    "    r4 = [x + barWidth for x in r3]\n",
    "    r5 = [x + barWidth for x in r4]\n",
    "    r6 = [x + barWidth for x in r5]\n",
    "\n",
    "    # Make the plot\n",
    "    plt.bar(r1, msf_prob, width=barWidth, edgecolor='white', label='MsFragger Peptide Prophet Probability')\n",
    "    plt.bar(r2, MM_qval, width=barWidth, edgecolor='white', label='MetaMorpheus Q-Value')\n",
    "    plt.bar(r3, msg_qval, width=barWidth, edgecolor='white', label='MsgfPlus Q-Value')\n",
    "    plt.bar(r4, mq_PEP, width=barWidth, edgecolor='white', label='MaxQuant PEP')\n",
    "    plt.bar(r5, MM_PEP, width=barWidth, edgecolor='white', label='MetaMorpheus PEP')\n",
    "    plt.bar(r6, input_prob, width=barWidth, edgecolor='white', label='Input ' + input_probability)\n",
    "\n",
    "\n",
    "    # Add xticks on the middle of the group bars\n",
    "    plt.ylabel('#PSMs')\n",
    "    plt.xlabel('# PSMs using native score and cutoff')\n",
    "    plt.title('0.2ng')\n",
    "    plt.xticks([r + barWidth for r in range(len(msf_prob))], ['File1', 'File2', 'File3', 'File4', 'File5', 'File6'])\n",
    "\n",
    "    # Create legend & Show graph\n",
    "    plt.legend(loc = \"upper right\", bbox_to_anchor=(1.73, 1))\n",
    "    plt.show()\n",
    "    #plt.savefig('0.2ng_PSM_native_score.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names of all the files we are going to read in to upload our data\n",
    "preMP_data = [\"2ng_rep1\"] #, \"2ng_rep2\", \"2ng_rep3\", \"2ng_rep4\", \"2ng_rep5\", \"2ng_rep6\",\n",
    "             #\"0.2ng_rep1\", \"0.2ng_rep2\", \"0.2ng_rep3\", \"0.2ng_rep4\", \"0.2ng_rep5\", \"0.2ng_rep6\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is split into 12 output files. We will read in the data one output file at a time for each tool and make a megascript. The megascript allows us to look at the output for each tool from that specific raw input file. \n",
    "\n",
    "We begin by reading in the output file from each tool. These are the output files that each tool gives us from running a specific raw file. We will then set the index to the scan column for each of the individual dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the .py script, this has been renamed to make_megascript\n",
    "\n",
    "def compare_data(input_files, cutoff, probability):\n",
    "\n",
    "    for file in preMP_data:\n",
    "\n",
    "        mm_df = get_orgininal_mm_data(file)\n",
    "        msf_df = get_original_msf_data(file)\n",
    "        msg_df = get_original_msg_data(file)\n",
    "        mq_df = get_original_mq_data(file)\n",
    "\n",
    "        #Switching index to ScanNr to join dataframes based on their scan numbers.  \n",
    "        MsgfPlus = msg_df.set_index('scan')\n",
    "        MsFragger = msf_df.set_index('scan')\n",
    "        MetaMorpheus = mm_df.set_index('scan')\n",
    "        MaxQuant = mq_df.set_index('scan')\n",
    "        \n",
    "\n",
    "        #concating all the individual joined dataframes togehter to make one megascript\n",
    "        megaScript = pd.concat(dict(MsFragger = MsFragger, MsgfPlus = MsgfPlus, MetaMorpheus = MetaMorpheus, \n",
    "                                    MaxQuant = MaxQuant), axis=1)\n",
    "        megaScript.reset_index(inplace=True)\n",
    "\n",
    "        #saving the megascript\n",
    "        megaScript.to_csv(\"benchmark_MegaScript_\" + file + \".csv\")\n",
    "        \n",
    "    #make the graphs\n",
    "#     make_2ng_graph(cutoff, probability)\n",
    "#     make_02ng_graph(cutoff, probability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to benchmark your program's output compared to our benchmarked you will need to run the same raw files  through your program. Begin by downloading six 2ng and six 0.2ng files from PRIDE (URL?). Run these through your program and save the files. \n",
    "\n",
    "In order to accuratly run your files against ours, each file will need to have a \"scan\", \"decoy\", and some type of probability column.\n",
    "- \"scan\" is the scan number column . \n",
    "- \"decoy\" is a boolean column that tracks whether a scan was tagged as a decoy or not. True denotes a deocy, others wise it will be false.\n",
    "- The probability column that presents the score that the tool gave to a specific scan. If your tool has a  qvalue or PEP value column, use this. (How to say that 0 is better than 1?) \n",
    "\n",
    "Once you have ran the raw files and saved the correctly formatted output files, insert the file paths into the correct spot in the input_files list below. Make sure that the right file is loaded into the right spot or your tool's output will not be correctly compared to the benchmarked data. \n",
    "\n",
    "**Not putting the peptide in\n",
    "\n",
    "The function to run the program will ask for the list of files, a cutoff, and the name of the probability column. The cutoff entered will be used to measure the number of PSM's at or below the cutoff.(need to say more eloquently)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = {} \n",
    "    #2ng files\n",
    "input_files[\"2ng_rep1\"] = \"Insert Ex_Auto_J3_30umTB_2ngQC_60m_1 file path\"\n",
    "input_files[\"2ng_rep2\"] = \"Insert Ex_Auto_J3_30umTB_2ngQC_60m_2 file path\"\n",
    "input_files[\"2ng_rep3\"] = \"Insert Ex_Auto_K13_30umTA_2ngQC_60m_1 file path\"\n",
    "input_files[\"2ng_rep4\"] = \"Insert Ex_Auto_K13_30umTA_2ngQC_60m_2 file path\"\n",
    "input_files[\"2ng_rep5\"] = \"Insert Ex_Auto_W17_30umTA_2ngQC_60m_3 file path\"\n",
    "input_files[\"2ng_rep6\"] = \"Insert Ex_Auto_W17_30umTA_2ngQC_60m_4 file path\"\n",
    "\n",
    "    #0.2ng files\n",
    "input_files[\"0.2ng_rep1\"] = \"Insert Ex_Auto_J3_30umTB_02ngQC_60m_1 file path\"\n",
    "input_files[\"0.2ng_rep2\"] = \"Insert Ex_Auto_J3_30umTB_02ngQC_60m_2 file path\"\n",
    "input_files[\"0.2ng_rep3\"] = \"Insert Ex_Auto_K13_30umTA_02ngQC_60m_1 file path\"\n",
    "input_files[\"0.2ng_rep4\"] = \"Insert Ex_Auto_K13_30umTA_02ngQC_60m_2 file path\"\n",
    "input_files[\"0.2ng_rep5\"] = \"Insert Ex_Auto_W17_30umTA_02ngQC_60m_3 file path\"\n",
    "input_files[\"0.2ng_rep6\"] = \"Insert Ex_Auto_W17_30umTA_02ngQC_60m_4 file path\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For testing only. Remove later\n",
    "#2ng files\n",
    "input_files[\"2ng_rep1\"] = \"2ng_rep1_new_features.csv\"\n",
    "input_files[\"2ng_rep2\"] = \"2ng_rep1_new_features.csv\"\n",
    "input_files[\"2ng_rep3\"] = \"2ng_rep1_new_features.csv\"\n",
    "input_files[\"2ng_rep4\"] = \"2ng_rep1_new_features.csv\"\n",
    "input_files[\"2ng_rep5\"] = \"2ng_rep1_new_features.csv\"\n",
    "input_files[\"2ng_rep6\"] = \"2ng_rep1_new_features.csv\"\n",
    "\n",
    "    #0.2ng files\n",
    "input_files[\"0.2ng_rep1\"] = \"2ng_rep1_new_features.csv\"\n",
    "input_files[\"0.2ng_rep2\"] = \"2ng_rep1_new_features.csv\"\n",
    "input_files[\"0.2ng_rep3\"] = \"2ng_rep1_new_features.csv\"\n",
    "input_files[\"0.2ng_rep4\"] = \"2ng_rep1_new_features.csv\"\n",
    "input_files[\"0.2ng_rep5\"] = \"2ng_rep1_new_features.csv\"\n",
    "input_files[\"0.2ng_rep6\"] = \"2ng_rep1_new_features.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will take the input data and will make the 2ng and 0.2ng graphs comparing the inputted data to our benchamarked data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-f9be1ed30239>:1: DtypeWarning: Columns (19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  compare_data(input_files, 0.01, \"probability\")\n"
     ]
    }
   ],
   "source": [
    "compare_data(input_files, 0.01, \"probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete from here down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daishavanderwatt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3343: DtypeWarning: Columns (19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "../data_loader.py:202: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['temp_peptide'] = df.apply(lambda row: format_oxidation(row, \"Modified sequence\", \"(Oxidation (M))\"), axis=1)\n",
      "../data_loader.py:203: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"temp_peptide\"] = df[\"temp_peptide\"].str[1:-1]\n",
      "../data_loader.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Reverse'] = df['Reverse'].astype(str)\n",
      "../data_loader.py:206: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"decoy\"] = df.apply(lambda row: make_decoy_col_maxquant(row), axis=1)\n"
     ]
    }
   ],
   "source": [
    "for file in preMP_data:\n",
    "\n",
    "    mm_df = get_orgininal_mm_data(file)\n",
    "    msf_df = get_original_msf_data(file)\n",
    "    msg_df = get_original_msg_data(file)\n",
    "    mq_df = get_original_mq_data(file)\n",
    "\n",
    "    #Switching index to ScanNr to join dataframes based on their scan numbers.  \n",
    "    MsgfPlus = msg_df.set_index('scan')\n",
    "    MsFragger = msf_df.set_index('scan')\n",
    "    MetaMorpheus = mm_df.set_index('scan')\n",
    "    MaxQuant = mq_df.set_index('scan')\n",
    "\n",
    "\n",
    "    #concating all the individual joined dataframes togehter to make one megascript\n",
    "    megaScript = pd.concat(dict(MsFragger = MsFragger, MsgfPlus = MsgfPlus, MetaMorpheus = MetaMorpheus, \n",
    "                                MaxQuant = MaxQuant), axis=1)\n",
    "    megaScript.reset_index(inplace=True)\n",
    "\n",
    "    #saving the megascript\n",
    "    megaScript.to_csv(\"benchmark_MegaScript_\" + file + \".csv\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>scan</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MsFragger</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MsgfPlus</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MetaMorpheus</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MaxQuant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>peptide</th>\n",
       "      <th>Updated_probability</th>\n",
       "      <th>peptide</th>\n",
       "      <th>QValue</th>\n",
       "      <th>peptide</th>\n",
       "      <th>QValue</th>\n",
       "      <th>PEP</th>\n",
       "      <th>peptide</th>\n",
       "      <th>PEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QSKSEHETSDAKKSVEDRGKRCPTPEIQK</td>\n",
       "      <td>0.086185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SSKAYYVLSDAAMSLQKYGR</td>\n",
       "      <td>3.24090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LSLLVAQEVTRLLDILGLTLVMK</td>\n",
       "      <td>5.57320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTMAPFWAHSDPEEM+15.995QWR</td>\n",
       "      <td>0.307555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELIVLLLVAAAHLR</td>\n",
       "      <td>0.45389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RTEDCGHCDFCRDMKK</td>\n",
       "      <td>0.303415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MMQCVLHVYK</td>\n",
       "      <td>0.11660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41802</th>\n",
       "      <td>9990</td>\n",
       "      <td>LDDPSCPRPECYR</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41803</th>\n",
       "      <td>9991</td>\n",
       "      <td>SDPVVSYR</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41804</th>\n",
       "      <td>9992</td>\n",
       "      <td>DTQEVPLEK</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41805</th>\n",
       "      <td>9994</td>\n",
       "      <td>RLEFENQK</td>\n",
       "      <td>0.3401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41806</th>\n",
       "      <td>9999</td>\n",
       "      <td>LGVTANDVK</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41807 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       scan      MsFragger                                           MsgfPlus  \\\n",
       "                   peptide Updated_probability                        peptide   \n",
       "0         5            NaN                 NaN  QSKSEHETSDAKKSVEDRGKRCPTPEIQK   \n",
       "1         7            NaN                 NaN                            NaN   \n",
       "2         8            NaN                 NaN      CTMAPFWAHSDPEEM+15.995QWR   \n",
       "3        11            NaN                 NaN               RTEDCGHCDFCRDMKK   \n",
       "4        13            NaN                 NaN                            NaN   \n",
       "...     ...            ...                 ...                            ...   \n",
       "41802  9990  LDDPSCPRPECYR              0.0000                            NaN   \n",
       "41803  9991       SDPVVSYR              0.0024                            NaN   \n",
       "41804  9992      DTQEVPLEK              0.0022                            NaN   \n",
       "41805  9994       RLEFENQK              0.3401                            NaN   \n",
       "41806  9999      LGVTANDVK              0.0003                            NaN   \n",
       "\n",
       "                MetaMorpheus                            MaxQuant           \n",
       "         QValue      peptide QValue PEP                  peptide      PEP  \n",
       "0      0.086185          NaN    NaN NaN     SSKAYYVLSDAAMSLQKYGR  3.24090  \n",
       "1           NaN          NaN    NaN NaN  LSLLVAQEVTRLLDILGLTLVMK  5.57320  \n",
       "2      0.307555          NaN    NaN NaN           ELIVLLLVAAAHLR  0.45389  \n",
       "3      0.303415          NaN    NaN NaN                      NaN      NaN  \n",
       "4           NaN          NaN    NaN NaN               MMQCVLHVYK  0.11660  \n",
       "...         ...          ...    ...  ..                      ...      ...  \n",
       "41802       NaN          NaN    NaN NaN                      NaN      NaN  \n",
       "41803       NaN          NaN    NaN NaN                      NaN      NaN  \n",
       "41804       NaN          NaN    NaN NaN                      NaN      NaN  \n",
       "41805       NaN          NaN    NaN NaN                      NaN      NaN  \n",
       "41806       NaN          NaN    NaN NaN                      NaN      NaN  \n",
       "\n",
       "[41807 rows x 10 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megaScript "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    " megaScript.to_csv(\"deleteMe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-885da5f977bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmi_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmi_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"Unnamed: 0_level_0\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmid_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmi_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmi_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4349\u001b[0m                 )\n\u001b[1;32m   4350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4351\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index_from_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverify_integrity\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index_from_sequences\u001b[0;34m(sequences, names)\u001b[0m\n\u001b[1;32m   5287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5288\u001b[0m             \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5289\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;31m# maybe coerce to a sub-class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_signed_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mInt64Index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_unsigned_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mUInt64Index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/numeric.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# GH#13601, GH#20285, GH#27125\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Index data must be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_extract_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Index data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "mi_df = pd.read_csv(\"deleteMe.csv\", header=[0,1])\n",
    "\n",
    "mi_df = mi_df.drop(columns = {\"Unnamed: 0_level_0\"})\n",
    "mid_df = mi_df.set_index('scan')\n",
    "mi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
