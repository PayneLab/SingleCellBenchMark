{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to calculate the number of consecutive y peaks, and the percent of annotated peaks in a consecutive series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import data_loader as dl\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_y_peaks(row):\n",
    "    enumeration = []\n",
    "    Y_and_B = row[\"Matched Ion Series\"].split(\";\")\n",
    "    \n",
    "    if len(Y_and_B) == 2: #if there are y and b peaks\n",
    "        if \"y\" in Y_and_B[1]:\n",
    "            peaks = Y_and_B[1]\n",
    "        elif \"y\" in Y_and_B[0]:\n",
    "            peaks = Y_and_B[0]\n",
    "            \n",
    "        peak_list = peaks.strip('][').split(\",\")\n",
    "\n",
    "        for peak in peak_list:\n",
    "            enumer_string = peak.split(\"+\")[0]\n",
    "            enumer = int(re.search(r'\\d+', enumer_string).group(0))\n",
    "            enumeration.append(enumer)\n",
    "                \n",
    "    else: #if there are either y or b peaks\n",
    "        if \"y\" in Y_and_B[0]: #if it's a y peak\n",
    "            peaks = Y_and_B[0]\n",
    "            peak_list = peaks.strip('][').split(\",\")\n",
    "\n",
    "            for peak in peak_list:\n",
    "                enumer_string = peak.split(\"+\")[0]\n",
    "                enumer = int(re.search(r'\\d+', enumer_string).group(0))\n",
    "                enumeration.append(enumer)\n",
    "        \n",
    "        else: #if it's a b peak\n",
    "            pass\n",
    "\n",
    "        \n",
    "    return enumeration  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_b_peaks(row):\n",
    "    enumeration = []\n",
    "    Y_and_B = row[\"Matched Ion Series\"].split(\";\")\n",
    "    \n",
    "    if len(Y_and_B) == 2: #if there are y and b peaks\n",
    "        if \"b\" in Y_and_B[1]:\n",
    "            peaks = Y_and_B[1]\n",
    "        elif \"b\" in Y_and_B[0]:\n",
    "            peaks = Y_and_B[0]\n",
    "            \n",
    "        peak_list = peaks.strip('][').split(\",\")\n",
    "\n",
    "        for peak in peak_list:\n",
    "            enumer_string = peak.split(\"+\")[0]\n",
    "            enumer = int(re.search(r'\\d+', enumer_string).group(0))\n",
    "            enumeration.append(enumer)\n",
    "                \n",
    "    else: #if there are either y or b peaks\n",
    "        if \"b\" in Y_and_B[0]: #if it's a b peak\n",
    "            peaks = Y_and_B[0]\n",
    "            peak_list = peaks.strip('][').split(\",\")\n",
    "\n",
    "            for peak in peak_list:\n",
    "                enumer_string = peak.split(\"+\")[0]\n",
    "                enumer = int(re.search(r'\\d+', enumer_string).group(0))\n",
    "                enumeration.append(enumer)\n",
    "        \n",
    "        else: #if it's a y peak\n",
    "            pass\n",
    "\n",
    "        \n",
    "    return enumeration    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_consecutive(row, col_name):\n",
    "    peak_list = row[col_name]\n",
    "    retlist = []\n",
    "    count = 1\n",
    "    # Avoid IndexError for  random_list[i+1]\n",
    "    for i in range(len(peak_list) - 1):\n",
    "        # Check if the next number is consecutive\n",
    "        if peak_list[i] + 1 == peak_list[i+1]:\n",
    "            count += 1\n",
    "        else:\n",
    "            # If it is not append the count and restart counting\n",
    "            retlist.append(count)\n",
    "            count = 1\n",
    "    # Since we stopped the loop one early append the last count\n",
    "    retlist.append(count)\n",
    "    return retlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_consec(row, col_name):\n",
    "    return max(row[col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc_ladder_peaks(row):\n",
    "    peak_link_list = row['Ypeak_enum']\n",
    "    consec_peak_list = row['consecutive_y_peaks']\n",
    "    consec_peak_list = list(filter(lambda a: a != 1, consec_peak_list))\n",
    "    if len(peak_link_list) == 0:\n",
    "        perc = -1 #this is for when there no Y peaks\n",
    "    else:\n",
    "        perc = sum(consec_peak_list)/len(peak_link_list)\n",
    "    return perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_consecutive_peaks(df):\n",
    "    sc = df[['scan','Matched Ion Series', 'QValue', 'peptide']]\n",
    "\n",
    "    sc = sc.assign(Bpeak_enum = sc.apply(enumerate_b_peaks, axis=1))\n",
    "\n",
    "    sc = sc.assign(consecutive_b_peaks = sc.apply(lambda row: count_consecutive(row, 'Bpeak_enum'), axis=1))\n",
    "\n",
    "    sc[\"Ypeak_enum\"] = sc.apply(enumerate_y_peaks, axis=1)\n",
    "    sc['consecutive_y_peaks'] = sc.apply(lambda row: count_consecutive(row, 'Ypeak_enum'), axis=1)\n",
    "\n",
    "    sc['max_consecutive_b'] = sc.apply(lambda row: get_max_consec(row, \"consecutive_b_peaks\"), axis=1)\n",
    "    sc['max_consecutive_y'] = sc.apply(lambda row: get_max_consec(row, \"consecutive_y_peaks\"), axis=1)\n",
    "\n",
    "    sc['perc_in_ladder'] = sc.apply(perc_ladder_peaks, axis=1)\n",
    "#     sc = sc[['scan','max_consecutive_b','max_consecutive_y','perc_in_ladder', 'QValue', 'peptide']] \n",
    "\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [\"2ng_rep1\", \"2ng_rep2\", \"2ng_rep3\", \"2ng_rep4\", \"2ng_rep5\", \"2ng_rep6\", \"0.2ng_rep1\", \"0.2ng_rep2\", \"0.2ng_rep3\", \"0.2ng_rep4\", \"0.2ng_rep5\", \"0.2ng_rep6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in all_files:\n",
    "    df = dl.clean_metamorph(file)\n",
    "    data = calc_consecutive_peaks(df)\n",
    "    data.to_csv(\"peaks_files/\" + file + \"_peaks_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
